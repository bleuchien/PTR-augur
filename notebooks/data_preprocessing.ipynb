{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1beab998-5752-460c-88cc-811abeffc8e2",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Overview\n",
    "\n",
    "The raw data from Eraslan et al. is a tab separated table containing gene names, related Ensembl IDs and measured or calculated values for mRNA abundance, protein abundance and protein-to-mRNA ratio.\n",
    "\n",
    "In the first Jupyter cells the data is roughly explored. After that the relevant values for the up coming analysis are extracted.\n",
    "\n",
    "Some problems arose:\n",
    "- Not all transcript IDs seem to be the current canonical form of transcript for a particular gene. In fact the given IDs point to transcripts that do not translate (in most cases). The gene needs to be identified in that case and the up to date transcript ID resolved.\n",
    "- BUT there are still some transcript IDs left that are annotate with \"nonsense mediated decay\". These will be thrown out as they do not successfully translate. \n",
    "- The Genecode data set contains duplicate files for some of the given transcript IDs. They can be easily filtered using a regex. The duplicates are the exact same files with different names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb525e9-e717-4129-99a3-89e5873b20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e3b47d-618e-4b6c-9d5a-7ef18c8bbac4",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f0e17-2ae6-42ec-b039-eeab545d756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data file and path\n",
    "datafile = '../data/Eraslan-EV3.tsv'\n",
    "\n",
    "# sanity check if the file exists\n",
    "if not Path(datafile).is_file():\n",
    "    print('Data file not found!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edbe60a-daa9-419a-8635-184aeb0dda89",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc2f0e8-62f4-4b85-912e-50b04cc3d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data into a dataframe and looking at the first entries\n",
    "df = pd.read_csv(datafile, sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10870254-b393-42b1-8a8d-7f38592b986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee1e23d-728a-4243-8050-f6b999fa2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de10a03-6d3e-4348-a970-1394d58ef4c6",
   "metadata": {},
   "source": [
    "Between ~3000 and ~4000 values in each of the 11575 rows are NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049d92a4-c181-43b9-81db-e2fbd4a7a9cd",
   "metadata": {},
   "source": [
    "## Extracting the relevant columns\n",
    "\n",
    "Only the _EnsemblTranscriptID_ and _PTR_ values per tissue are necessary for training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b83b9-4921-422f-b99e-622e830e56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['EnsemblTranscriptID'] + [ col for col in df.columns if col.endswith('_PTR') ]].copy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76fe860-fd42-43ec-9818-0ffab352701e",
   "metadata": {},
   "source": [
    "Cross referencing the transcript IDs with BED and Fasta files from the gencode data set (43).\n",
    "\n",
    "The path set below expects the gencode repo to be relative to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf60f0-d6e7-4955-b214-23454e27a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data paths\n",
    "gencode_path = '../../GENCODE43/protein_coding/'\n",
    "bed = Path(gencode_path) / 'BED6__protein_coding_strict/'\n",
    "fa = Path(gencode_path) / 'FA_protein_coding_strict_mRNA/'\n",
    "\n",
    "# file names look like this\n",
    "# for the BED file : ENST00000370801.8.bed\n",
    "# for the Fasta file : ENST00000370801.8:0-6412.fasta\n",
    "# .8 denotes the current Ensemble version\n",
    "# :0-6412 is the nucleotide length\n",
    "\n",
    "# count of processed transcript IDs\n",
    "count_all = 0\n",
    "# success count\n",
    "count_found = 0\n",
    "# multiple files found for transcript\n",
    "count_multi = 0\n",
    "\n",
    "# extend the dataframe\n",
    "# number of files found\n",
    "df2['bed_files'] = 0\n",
    "df2['fa_files'] = 0\n",
    "# file path and name\n",
    "df2['bed'] = ''\n",
    "df2['fa'] = ''\n",
    "\n",
    "# checking if all the transcript Fasta and BED files per transcript exist\n",
    "for tid in df2['EnsemblTranscriptID']:\n",
    "    # inclrease over all count\n",
    "    count_all += 1\n",
    "\n",
    "    # list and count files\n",
    "    bed_file_list = list(bed.glob(tid + '*.bed'))\n",
    "    bed_file_count = len(bed_file_list)\n",
    "    fa_file_list = list(fa.glob(tid + '*.fasta'))\n",
    "    fa_file_count = len(fa_file_list)\n",
    "\n",
    "    # update dataframe\n",
    "    df2.loc[ df2['EnsemblTranscriptID'] == tid, 'bed_files'] = bed_file_count\n",
    "    df2.loc[ df2['EnsemblTranscriptID'] == tid, 'fa_files'] = fa_file_count\n",
    "\n",
    "    # check BED and Fasta file count\n",
    "    if bed_file_count == 1 and fa_file_count == 1:\n",
    "        # exctly one BED and FA file\n",
    "        \n",
    "        # increase hit count\n",
    "        count_found += 1\n",
    "        \n",
    "        # update file name information\n",
    "        df2.loc[ df2['EnsemblTranscriptID'] == tid, 'bed'] = str(bed_file_list[0])\n",
    "        df2.loc[ df2['EnsemblTranscriptID'] == tid, 'fa'] = str(fa_file_list[0])\n",
    "    elif bed_file_count == 2 and fa_file_count == 2:\n",
    "        # special case where there are duplicate files\n",
    "        print(tid, 'more than one BED/Fasta file present. selecting')\n",
    "\n",
    "        # increase hit count\n",
    "        count_found += 1\n",
    "        count_multi += 1\n",
    "\n",
    "        # find correct BED file and update table\n",
    "        for f in bed_file_list:\n",
    "            temp_bed_file = str(f)\n",
    "            if re.search(r'.*ENST\\d+\\.\\d+.bed', temp_bed_file):\n",
    "                df2.loc[ df2['EnsemblTranscriptID'] == tid, 'bed'] = temp_bed_file\n",
    "                print('   ', temp_bed_file)\n",
    "\n",
    "        # find correct Fasta file and update table\n",
    "        for f in fa_file_list:\n",
    "            temp_fa_file = str(f)\n",
    "            if re.search(r'.*ENST\\d+\\.\\d+:\\d+-\\d+.fasta', temp_fa_file):\n",
    "                df2.loc[ df2['EnsemblTranscriptID'] == tid, 'fa'] = temp_fa_file\n",
    "                print('   ', temp_fa_file)\n",
    "\n",
    "        # update file count in table\n",
    "        df2.loc[ df2['EnsemblTranscriptID'] == tid, 'bed_files'] = 1\n",
    "        df2.loc[ df2['EnsemblTranscriptID'] == tid, 'fa_files'] = 1\n",
    "    else:\n",
    "        # everything else ends up here\n",
    "        print(tid, 'bed count:', bed_file_count, 'fa count:', fa_file_count, 'bed files:', bed_file_list, 'fa files:', fa_file_list)\n",
    "\n",
    "print('searched for', count_all, 'and found', count_found)\n",
    "print('found multiple files for', count_multi, 'transcripts')\n",
    "print('missing or otherwise off:', count_all - count_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba103ec0-a297-43fe-a45d-ba6d1b8b493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entries with two transcript files per entry\n",
    "# the gencod data set contains a couple of transcript files with multiple different names\n",
    "# file countent is exaclty the same\n",
    "# this has been corrected in the previous cell so this sanity check should reveal 0 rows\n",
    "df2.loc[ df2['bed_files'] == 2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd8bba-8966-4f95-98c4-b5942e0b07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the number of missing files (with a count of 0 in the bed_file column)\n",
    "df2.loc[ df2['bed_files'] == 0, 'EnsemblTranscriptID' ].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda9f82-6566-4955-b960-c675b07cbf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some of the IDs with missing files\n",
    "df2.loc[ df2['bed_files'] == 0, 'EnsemblTranscriptID' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a232ea0-92dd-453c-9089-c1fda02ac35d",
   "metadata": {},
   "source": [
    "Sampling the IDs for which files are missing showed that the transcript is either deprecated or not the canonical form in the gencode data set (43). For 11 IDs there are no corresponding transcript entries any more.\n",
    "\n",
    "This is a natural evolution since the Eraslan et al. research took place 2019 the underlying data in the Ensembl database got updated with current research results.\n",
    "\n",
    "The following cells query the Ensembl web site directly for the transcript IDs in question as it's the fastest way to resolve this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fef2af9-93d4-4b84-b41f-0e2afecb8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_transcript(req):\n",
    "    \"\"\"Method to extract a specific transcript ID from an HTML document.\n",
    "\n",
    "    Keyword Arguments:\n",
    "    req -- Python request object\n",
    "\n",
    "    Returns:\n",
    "    A string either empty or containing the transcript ID.\n",
    "    \"\"\"\n",
    "    # parse the HTML document\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    # check if a specific table exists\n",
    "    if soup.find(id='transcripts_table'):\n",
    "        # if so extract the transcript ID\n",
    "        href = soup.find(id='transcripts_table').tbody.td.a.attrs['href']\n",
    "        transcript = re.sub(r'.*(ENST0\\d+)', r'\\1', href)\n",
    "        print('   Current canonical transcript is', transcript)\n",
    "    else:\n",
    "        # if not return an empty string\n",
    "        transcript = ''\n",
    "        print('   No current transcript found!')\n",
    "\n",
    "    return transcript\n",
    "\n",
    "def check_files_and_update_df(transcript):\n",
    "    \"\"\"Cross reference the transcript ID with files in the gencode data set\n",
    "    (bad hack as it uses variables globally defined at the beginning of this notebook!)\n",
    "\n",
    "    Keyword Arguments:\n",
    "    transcript -- the transcript ID string\n",
    "    \"\"\"\n",
    "    # search and count files with a given name\n",
    "    bed_file_list = list(bed.glob(transcript + '*.bed'))\n",
    "    bed_files = len(bed_file_list)\n",
    "    fa_file_list = list(fa.glob(transcript + '*.fasta'))\n",
    "    fa_files = len(fa_file_list)\n",
    "\n",
    "    # check how many files were found\n",
    "    if bed_files == 1 and fa_files == 1:\n",
    "        # if it's 1 everything is perfect\n",
    "        print('   FA and BED files found. Updating dataframe with current information')\n",
    "        # update dataframe\n",
    "        df2.loc[ df2['EnsemblTranscriptID'] == tid, 'bed_files' ] = bed_files\n",
    "        df2.loc[ df2['EnsemblTranscriptID'] == tid, 'fa_files' ] = fa_files\n",
    "        df2.loc[ df2['EnsemblTranscriptID'] == tid, 'EnsemblTranscriptID' ] = transcript\n",
    "    else:\n",
    "        # if there are many manual processing is needed\n",
    "        print('   FA and BED file count invalid. File lists', bed_file_list, fa_file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35c17e-5712-446e-97f7-1ccde66b5c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all transcript IDs without a transcript file associated with it\n",
    "for tid in df2.loc[ df2['bed_files'] == 0, 'EnsemblTranscriptID' ]: #.head(2):\n",
    "    print('processing', tid)\n",
    "    # Ensembl URL for resolving the given transcript ID\n",
    "    url = 'https://www.ensembl.org/Homo_sapiens/Transcript/Idhistory?t=' + tid\n",
    "    # retrieve the document\n",
    "    r = requests.get(url)\n",
    "    # parse the document\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    # check for specific strings in the page\n",
    "    if re.search(r'This transcript is not in the current gene set', soup.get_text()):\n",
    "        # transcript is deprecated so extract the corresponding gene and get the canonical transcript ID\n",
    "        href = soup.td.next_sibling.a.attrs['href']\n",
    "        gene = re.sub(r'.*(ENSG0\\d+)', r'\\1', href)\n",
    "        print('   Transcript is deprecated, resolved gene is', gene)\n",
    "\n",
    "        # Ensembl URL to resolve a gene ID\n",
    "        url = 'https://www.ensembl.org/Homo_sapiens/Gene/Idhistory?g=' + gene\n",
    "        r = requests.get(url)\n",
    "        transcript = find_new_transcript(r)\n",
    "        check_files_and_update_df(transcript)\n",
    "    elif re.search(r'Show transcript table', soup.get_text()):\n",
    "        # the transcript is not the current canonical version and needs updating\n",
    "        transcript = find_new_transcript(r)\n",
    "        check_files_and_update_df(transcript)\n",
    "    else:\n",
    "        print('   Some other error occured for this transcript')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fbc22-ba69-4063-a639-cd7023e68465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are still entries with unresolved transcript files\n",
    "# spoiler, there are 11\n",
    "df2.loc[ df2['bed_files'] == 0, 'EnsemblTranscriptID' ].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c2034c-e9a1-414a-a3aa-4379e25515d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the 11 IDs with missing transcript files\n",
    "df2.loc[ df2['bed_files'] == 0 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f006f00f-d749-420a-9624-7ec1c65b5d66",
   "metadata": {},
   "source": [
    "Even though these transcript IDs will have resolved in 2019 when the paper using this data was published the current database does not resolve these IDs any more (due to more up to date research results).\n",
    "\n",
    "Being brave those entries will be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f12fc-f489-4b9a-a47d-5abfec3006cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 11 missing entries\n",
    "df2.drop(df2[df2['bed_files'] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ac807-72f6-49e4-a591-f3f02bcd5711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the entries are gone from the dataframe\n",
    "df2.loc[ df2['bed_files'] == 0 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f910f9c-58c4-49a3-9466-bc734035ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write current pre processed table to file\n",
    "datafile = '../data/preproc.csv'\n",
    "df2.to_csv(datafile, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
