{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1ce73b25-d36d-413d-a323-67e9a246b21b",
      "metadata": {
        "id": "1ce73b25-d36d-413d-a323-67e9a246b21b"
      },
      "source": [
        "# Full Neural Network Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive'\n",
        "nb_path = base_path + '/MyDrive/PTR-augur/notebooks'"
      ],
      "metadata": {
        "id": "mSAF7MIQ-z1n"
      },
      "id": "mSAF7MIQ-z1n",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(base_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_Z0HQD-_nXw",
        "outputId": "e50b6dbc-55c3-47d8-a054-f1b94b939ed2"
      },
      "id": "F_Z0HQD-_nXw",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2874d9ad-1cd5-4f33-bcf6-178552b4ecc4",
      "metadata": {
        "id": "2874d9ad-1cd5-4f33-bcf6-178552b4ecc4"
      },
      "outputs": [],
      "source": [
        "# library dependencies\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import lzma\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "import keras\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "# import keras_tuner\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7b634de2-ee59-4979-ae29-9ce9ab8a2909",
      "metadata": {
        "id": "7b634de2-ee59-4979-ae29-9ce9ab8a2909"
      },
      "outputs": [],
      "source": [
        "# method to store data as serialized binary structure lzma compressed\n",
        "def can_pickles(data, filename):\n",
        "    with lzma.LZMAFile(filename, 'wb') as f:\n",
        "        pickle.dump(data, f, pickle.DEFAULT_PROTOCOL)\n",
        "\n",
        "# method to retrieve data from a compressed pickle file (created with the method above)\n",
        "def uncan_pickles(filename):\n",
        "    with lzma.LZMAFile(filename, 'rb') as f:\n",
        "        return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "29c2a628-8756-4b25-844b-10352d9ce814",
      "metadata": {
        "id": "29c2a628-8756-4b25-844b-10352d9ce814"
      },
      "outputs": [],
      "source": [
        "# helper method to create a valid dataset\n",
        "# padded batches from ragged tensors are not supported (yet)\n",
        "# it needs a work around creating a uniform tensor\n",
        "# idea from : https://github.com/tensorflow/tensorflow/issues/39163\n",
        "def reformat(data, label):\n",
        "    return data, label\n",
        "\n",
        "# method to create a TF dataset\n",
        "def create_dataset(X1_np_array, X2_np_array, y_np_array, batch_size=32, sort=False, step_size=5):\n",
        "    # sort the arrays\n",
        "    if sort == True:\n",
        "        # build an array containing the sequence lengths\n",
        "        sequence_lengths = list(map(lambda x: len(x), X1_np_array))\n",
        "        # sort the array but only get the indices\n",
        "        sorted_indices = np.argsort(sequence_lengths)\n",
        "        # now sort the X and y train arrays according to the sorted indicds\n",
        "        X1_np_array = X1_np_array[sorted_indices]\n",
        "        X2_np_array = X2_np_array[sorted_indices]\n",
        "        y_np_array = y_np_array[sorted_indices]\n",
        "\n",
        "    # create ragged tensor from in-homogeneous array\n",
        "    # using .constant is incredibly slow, even slower with parameters\n",
        "    # ie. 100 samples take 7 seconds, with parameters it takes 11 seconds\n",
        "    # using the following method that seems nuts it's a speedup for the previous example to 0.02 seconds\n",
        "    # X_tensor = tf.ragged.constant(X1_np_array, dtype=tf.int8, ragged_rank=1, row_splits_dtype=tf.int32)\n",
        "    # https://github.com/tensorflow/tensorflow/issues/47853\n",
        "    # with tf.device('/device:cpu:0'):\n",
        "    X_tensor = tf.RaggedTensor.from_row_lengths(\n",
        "        values=tf.concat(X1_np_array.tolist(), axis=0),\n",
        "        row_lengths=[len(a) for a in X1_np_array]\n",
        "    )\n",
        "\n",
        "    # hack to work around a GPU out of memory problem\n",
        "    # X_tensor = None\n",
        "    # step_size = step_size\n",
        "    # steps = math.ceil(len(X1_np_array) / step_size)\n",
        "    # for i in range(steps):\n",
        "    #   start = step_size * i\n",
        "    #   stop = step_size * (i + 1)\n",
        "    #   if stop > len(X1_np_array): stop = len(X1_np_array)\n",
        "    #   # print(f'start {start} - stop {stop}')\n",
        "\n",
        "    #   sub_X1_np_array = X1_np_array[start:stop]\n",
        "\n",
        "    #   foo = tf.RaggedTensor.from_row_lengths(\n",
        "    #       values=tf.concat(sub_X1_np_array.tolist(), axis=0),\n",
        "    #       row_lengths=[len(a) for a in sub_X1_np_array]\n",
        "    #   )\n",
        "\n",
        "    #   if X_tensor == None:\n",
        "    #     X_tensor = foo\n",
        "    #   else:\n",
        "    #     X_tensor = tf.concat([X_tensor, foo], axis=0)\n",
        "\n",
        "\n",
        "    # create dataset\n",
        "    ds = tf.data.Dataset.from_tensor_slices(({'inputs_1': X_tensor, 'inputs_2': X2_np_array}, y_np_array))\n",
        "\n",
        "    # create a dataset of dense tensors\n",
        "    ds = ds.map(reformat)\n",
        "\n",
        "    # apply padded batching to the dataset\n",
        "    ds = ds.padded_batch(batch_size)\n",
        "\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d13c3c1f-0eef-41c7-a4cb-8f1287335b64",
      "metadata": {
        "id": "d13c3c1f-0eef-41c7-a4cb-8f1287335b64"
      },
      "outputs": [],
      "source": [
        "_# method to plot two MAE arrays\n",
        "def plot_loss(train_mae, val_mae, start_epoch=1):\n",
        "    # get the number of epochs the training ran\n",
        "    epochs = range(start_epoch, len(train_mae) + 1)\n",
        "    # plot the graph\n",
        "    plt.plot(epochs, train_mae, \"bo\", label=\"Training\")\n",
        "    plt.plot(epochs, val_mae, \"b\", label=\"Validation\")\n",
        "    plt.title(\"Training and Validation Mean Absolute Error\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"MAE\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "57ee08f6-464e-4492-9931-69e754ab2d40",
      "metadata": {
        "id": "57ee08f6-464e-4492-9931-69e754ab2d40"
      },
      "outputs": [],
      "source": [
        "# model to work with\n",
        "# from keras-tuner run:\n",
        "#   conv_units: 424\n",
        "#   kernel_size: 30\n",
        "#   rate: 0.30000000000000004\n",
        "#   dense_units: 128\n",
        "def augur_model():\n",
        "    inputs_1 = layers.Input(shape=(None, 10), name='inputs_1')\n",
        "\n",
        "    conv1 = layers.Conv1D(\n",
        "        filters=424,\n",
        "        kernel_size=30,\n",
        "        strides=1,\n",
        "        activation='relu',\n",
        "        padding='valid'\n",
        "    )(inputs_1)\n",
        "    norm1 = layers.BatchNormalization()(conv1)\n",
        "    drop1 = layers.Dropout(\n",
        "        rate=0.3\n",
        "    )(norm1)\n",
        "    pool1 = layers.GlobalMaxPool1D()(drop1)\n",
        "    # flat = layers.Flatten()(pool1)\n",
        "\n",
        "    inputs_2 = layers.Input(shape=(29,), name='inputs_2')\n",
        "\n",
        "    conc = layers.Concatenate(axis=1)([pool1, inputs_2])\n",
        "\n",
        "    dense = layers.Dense(128, activation='relu')(conc)\n",
        "    outputs = layers.Dense(1)(dense)\n",
        "\n",
        "    model = keras.Model(inputs=[inputs_1, inputs_2], outputs=outputs, name='Test')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "81491a3c-2246-482f-ab53-c8ab281e24da",
      "metadata": {
        "id": "81491a3c-2246-482f-ab53-c8ab281e24da"
      },
      "outputs": [],
      "source": [
        "def dan_zrimec_model():\n",
        "    inputs_1 = layers.Input(shape=(None, 10), name='inputs_1')\n",
        "\n",
        "    # 1D convolution\n",
        "    conv = layers.Conv1D(\n",
        "        filters=280,\n",
        "        kernel_size=12,\n",
        "        strides=1,\n",
        "        activation='relu'\n",
        "    )(inputs_1)\n",
        "    # batch normalization\n",
        "    norm = layers.BatchNormalization()(conv)\n",
        "    # maxpool\n",
        "    pool = layers.MaxPooling1D(\n",
        "        pool_size=2,\n",
        "        strides=None\n",
        "    )(norm)\n",
        "    # dropout\n",
        "    drop = layers.Dropout(\n",
        "        rate=0.15\n",
        "    )(pool)\n",
        "    # bi-directional LSTM\n",
        "    bilstm = layers.Bidirectional(\n",
        "        layers.LSTM(\n",
        "            units=448,\n",
        "            return_sequences=True,\n",
        "            recurrent_dropout=0.3\n",
        "        ),\n",
        "        merge_mode='concat'\n",
        "        # input_shape=(8000, 4),\n",
        "    )(drop)\n",
        "    # maxpool\n",
        "    pool = layers.MaxPooling1D(\n",
        "        pool_size=2,\n",
        "        strides=None\n",
        "    )(bilstm)\n",
        "    drop = layers.Dropout(\n",
        "        rate=0.1\n",
        "    )(pool)\n",
        "    # flatten\n",
        "    # flat = layers.Flatten()(drop)\n",
        "    gmp = layers.GlobalMaxPool1D()(drop)\n",
        "\n",
        "    inputs_2 = layers.Input(shape=(29,), name='inputs_2')\n",
        "\n",
        "    conc = layers.Concatenate(axis=1)([gmp, inputs_2])\n",
        "\n",
        "    # fully connected\n",
        "    dense = layers.Dense(\n",
        "        units=128,\n",
        "        activation='relu',\n",
        "    )(conc)\n",
        "    # batch normalization\n",
        "    norm = layers.BatchNormalization()(dense)\n",
        "    # dropout\n",
        "    drop = layers.Dropout(\n",
        "        rate=0.45\n",
        "    )(norm)\n",
        "    # dense\n",
        "    outputs = layers.Dense(units=1)(drop)\n",
        "\n",
        "    # model\n",
        "    model = keras.Model(inputs=[inputs_1, inputs_2], outputs=outputs, name='FullModel')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a69600b6-8ab4-4080-8bce-64dbbb308151",
      "metadata": {
        "id": "a69600b6-8ab4-4080-8bce-64dbbb308151"
      },
      "outputs": [],
      "source": [
        "def run_model(model, train_ds, val_ds, epochs=10, start_epoch=1, oneshot=True, verbose=True):\n",
        "    if verbose:\n",
        "        model.summary()\n",
        "        verbose_fit = 'auto'\n",
        "    else:\n",
        "        verbose_fit = 0\n",
        "\n",
        "    model.compile(\n",
        "        loss=keras.losses.MeanSquaredError(),\n",
        "        optimizer=keras.optimizers.Adam(),\n",
        "        metrics=[keras.metrics.MeanAbsoluteError()],\n",
        "    )\n",
        "\n",
        "    callback = keras.callbacks.BackupAndRestore(backup_dir=nb_path + '/bar', save_freq='epoch')\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=epochs,\n",
        "        validation_data=val_ds,\n",
        "        verbose=verbose_fit,\n",
        "        callbacks=[callback]\n",
        "    )\n",
        "\n",
        "    if oneshot == True:\n",
        "        plot_loss(\n",
        "            history.history['mean_absolute_error'],\n",
        "            history.history['val_mean_absolute_error'],\n",
        "            start_epoch\n",
        "        )\n",
        "\n",
        "    if val_ds != None:\n",
        "        return history.history['mean_absolute_error'], history.history['val_mean_absolute_error']\n",
        "    else:\n",
        "        return history.history['mean_absolute_error']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bf21cd28-49ae-441a-9daa-8b0712296906",
      "metadata": {
        "id": "bf21cd28-49ae-441a-9daa-8b0712296906"
      },
      "outputs": [],
      "source": [
        "# simple timer from https://realpython.com/python-timer/\n",
        "\n",
        "class Timer:\n",
        "    def __init__(self):\n",
        "        self._start_time = None\n",
        "\n",
        "    def start(self):\n",
        "        \"\"\"Start a new timer\"\"\"\n",
        "        if self._start_time is not None:\n",
        "            print(f\"Timer is running. Use .stop() to stop it\")\n",
        "        else:\n",
        "            self._start_time = time.perf_counter()\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Stop the timer, and report the elapsed time\"\"\"\n",
        "        if self._start_time is None:\n",
        "            print(f\"Timer is not running. Use .start() to start it\")\n",
        "        else:\n",
        "            elapsed_time = time.perf_counter() - self._start_time\n",
        "            self._start_time = None\n",
        "            print(f\"    elapsed time: {elapsed_time:0.4f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf711275-0384-46df-9510-b7beaf2a2463",
      "metadata": {
        "id": "cf711275-0384-46df-9510-b7beaf2a2463"
      },
      "source": [
        "## Data Prep\n",
        "\n",
        "*explain it in more detail*\n",
        "\n",
        "X holds a list of sequences one hot encoded\n",
        "\n",
        "y holds a list of PTR values as floats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "198c44f7-050c-4c96-a00b-0b4fcbf2c9fb",
      "metadata": {
        "id": "198c44f7-050c-4c96-a00b-0b4fcbf2c9fb"
      },
      "outputs": [],
      "source": [
        "# read the prepared data back\n",
        "X1_raw = uncan_pickles(nb_path + '/../data/multihot_x1.pickle.xz')\n",
        "X2 = uncan_pickles(nb_path + '/../data/multihot_x2.pickle.xz')\n",
        "y = uncan_pickles(nb_path + '/../data/multihot_y.pickle.xz')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# refined numpy array build with smaller memory footprint\n",
        "X1 = np.empty(len(X1_raw), dtype=object)\n",
        "for id, seq in enumerate(X1_raw):\n",
        "  X1[id] = np.array(seq, dtype=np.int8)"
      ],
      "metadata": {
        "id": "CVtsw23Oj4YB"
      },
      "id": "CVtsw23Oj4YB",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7a77d5bf-bbc1-4c38-8466-c2904242880b",
      "metadata": {
        "id": "7a77d5bf-bbc1-4c38-8466-c2904242880b"
      },
      "outputs": [],
      "source": [
        "# build an inhomogenous numpy array from X\n",
        "# X1 = np.array(X1, dtype=object) # too high memory usage\n",
        "X2 = np.array(X2, dtype=np.int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "668f2ec1-e6df-4287-b0ab-442001a822b7",
      "metadata": {
        "id": "668f2ec1-e6df-4287-b0ab-442001a822b7"
      },
      "outputs": [],
      "source": [
        "# convert type of target values from string to float\n",
        "y = np.array(y, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d46f705-a1c2-4c59-ad0b-88ae2c943c7d",
      "metadata": {
        "id": "2d46f705-a1c2-4c59-ad0b-88ae2c943c7d"
      },
      "source": [
        "Random sample from X and y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d4c1a3a7-3751-4649-9d85-8e17255a4c03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4c1a3a7-3751-4649-9d85-8e17255a4c03",
        "outputId": "26d9da89-01f7-4d3b-bd8d-f69da074cdf1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0]], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X1[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "32f82f91-4bf2-4f29-8e12-92ba7196ea07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32f82f91-4bf2-4f29-8e12-92ba7196ea07",
        "outputId": "ec881465-4bd4-4236-8b5b-5bda7a54c7a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X2[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "784bb474-f719-45fe-8836-beaef80dc222",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "784bb474-f719-45fe-8836-beaef80dc222",
        "outputId": "26c195dd-f53f-42fc-a78a-001c4265ca81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.277"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "01e465cd-e5c3-41e1-889c-f82254879828",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01e465cd-e5c3-41e1-889c-f82254879828",
        "outputId": "4133f24c-051d-4dcf-cfca-b563ce3b7760"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(214853, 214853, 214853)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# count of features and labels\n",
        "len(X1), len(X2), len(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea0459c2-c83d-4920-a3d0-8c86f348a235",
      "metadata": {
        "id": "ea0459c2-c83d-4920-a3d0-8c86f348a235"
      },
      "source": [
        "### Baseline PTR\n",
        "\n",
        "There is no common sense approach in finding a baseline for the protein-to-mRNA ratio of a particular mRNA sequence. This is what the *Basic Neural Network* approach is for - to determin a baseline and see if a slightly adapted neural network with feature engineered input can provide better predictions.\n",
        "\n",
        "But what can be done is to simply check the value range of the target PTRs, calculate mean and standard deviation. Given that the standard deviation is  small (12.5% of the value range) one can (stupidly) predict the mean value every time. From that it's possible to calculate the Mean Absolute Error (MAE) and compare that to the following neural network output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "941624fc-a917-4983-bfdd-d58fb88f0a52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "941624fc-a917-4983-bfdd-d58fb88f0a52",
        "outputId": "3eeda352-6007-4ca3-a5e9-72dccecde21a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9085 9.974 4.9798956 0.8879484\n"
          ]
        }
      ],
      "source": [
        "# get some idea of the range of the PTR in the selected SAMPLE\n",
        "print(np.min(y), np.max(y), np.mean(y), np.std(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "28d58d39-da1d-4f25-8f43-770dd077ae7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28d58d39-da1d-4f25-8f43-770dd077ae7b",
        "outputId": "67aa46dd-a575-43da-f539-cc034a4f713a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7119917"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# simple/dumb baseline mean absolute error of always predicting 4.974\n",
        "mae = np.mean(np.abs(np.array(y) - 4.974))\n",
        "mae"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81105338-e17c-4c50-b9c8-19e022c857eb",
      "metadata": {
        "id": "81105338-e17c-4c50-b9c8-19e022c857eb"
      },
      "source": [
        "### Splits\n",
        "\n",
        "Split data in train and test sub sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f3bec3f9-c83c-4690-b56c-ae3b97b877d4",
      "metadata": {
        "id": "f3bec3f9-c83c-4690-b56c-ae3b97b877d4"
      },
      "outputs": [],
      "source": [
        "# split in train and test sub sets\n",
        "X1_train_full, X1_test, X2_train_full, X2_test, y_train_full, y_test = train_test_split(X1, X2, y, test_size=0.2, random_state=1202)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f4205acc-8876-4855-9cc9-8b5948dd15ba",
      "metadata": {
        "id": "f4205acc-8876-4855-9cc9-8b5948dd15ba"
      },
      "outputs": [],
      "source": [
        "# split the training set again in train and validation\n",
        "X1_train, X1_val, X2_train, X2_val, y_train, y_val = train_test_split(X1_train_full, X2_train_full, y_train_full, test_size=0.2, random_state=1202)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "582618a5-4e35-4998-acdf-84feff4d2f74",
      "metadata": {
        "id": "582618a5-4e35-4998-acdf-84feff4d2f74"
      },
      "outputs": [],
      "source": [
        "# batch_size = 64\n",
        "batch_size = 32 # reduced batch size due to memory problems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9f34c6b2-ff64-4861-918a-34c83e3a51ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f34c6b2-ff64-4861-918a-34c83e3a51ae",
        "outputId": "283c1567-4f45-4ad2-918c-1963a629f3c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10.7 s, sys: 2.63 s, total: 13.3 s\n",
            "Wall time: 12 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# build the test dataset\n",
        "test_ds = create_dataset(X1_test, X2_test, y_test, batch_size=batch_size, sort=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "fa335eb5-5d74-4c78-b192-414edc015645",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa335eb5-5d74-4c78-b192-414edc015645",
        "outputId": "3d329676-6ec7-485c-8084-e8b5600db376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 36.6 s, sys: 9.56 s, total: 46.2 s\n",
            "Wall time: 40.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# build the training dataset\n",
        "train_full_ds = create_dataset(X1_train_full, X2_train_full, y_train_full, batch_size=batch_size, sort=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6e139b14-a23f-4899-b85e-5fe7d80c49fb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e139b14-a23f-4899-b85e-5fe7d80c49fb",
        "outputId": "6c40693a-a6a5-4d09-f75d-a8cc906bf2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 29.7 s, sys: 5.48 s, total: 35.2 s\n",
            "Wall time: 30.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# build the training dataset\n",
        "train_ds = create_dataset(X1_train, X2_train, y_train, batch_size=batch_size, sort=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "783f52f5-022b-4991-8337-c5fd4062b4db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "783f52f5-022b-4991-8337-c5fd4062b4db",
        "outputId": "8ee21c5e-8923-4cb3-ce9c-c97678574cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.72 s, sys: 1.31 s, total: 9.02 s\n",
            "Wall time: 8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# build the validation dataset\n",
        "val_ds = create_dataset(X1_val, X2_val, y_val, batch_size=batch_size, sort=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85ac31aa-4582-45df-957c-d7aa0bb79449",
      "metadata": {
        "id": "85ac31aa-4582-45df-957c-d7aa0bb79449"
      },
      "outputs": [],
      "source": [
        "# NOT doing that any more since the speed up of the ragged tensor creation\n",
        "\n",
        "# save the previously generated dataset\n",
        "# since the ragged tensor creation takes a very, very long time\n",
        "# test_ds.save('../data/test_ds.tf.dataset')\n",
        "# train_full_ds.save('../data/train_full_ds.tf.dataset')\n",
        "# train_ds.save('../data/train_ds.tf.dataset')\n",
        "# val_ds.save('../data/val_ds.tf.dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16486337-06cf-4678-8a96-bde976a9df03",
      "metadata": {
        "id": "16486337-06cf-4678-8a96-bde976a9df03"
      },
      "source": [
        "## Full Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9840923-0fd8-4d3e-9472-bc6753de99a9",
      "metadata": {
        "id": "a9840923-0fd8-4d3e-9472-bc6753de99a9",
        "outputId": "4c789069-7afa-468b-b429-92fe5a7f52b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training model for 40\n",
            "Model: \"Test\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " inputs_1 (InputLayer)       [(None, None, 10)]           0         []                            \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, None, 424)            127624    ['inputs_1[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, None, 424)            1696      ['conv1d_7[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)         (None, None, 424)            0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " global_max_pooling1d_6 (Gl  (None, 424)                  0         ['dropout_6[0][0]']           \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " inputs_2 (InputLayer)       [(None, 29)]                 0         []                            \n",
            "                                                                                                  \n",
            " concatenate_6 (Concatenate  (None, 453)                  0         ['global_max_pooling1d_6[0][0]\n",
            " )                                                                  ',                            \n",
            "                                                                     'inputs_2[0][0]']            \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 128)                  58112     ['concatenate_6[0][0]']       \n",
            "                                                                                                  \n",
            " dense_9 (Dense)             (None, 1)                    129       ['dense_8[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 187561 (732.66 KB)\n",
            "Trainable params: 186713 (729.35 KB)\n",
            "Non-trainable params: 848 (3.31 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/40\n",
            "2149/2149 [==============================] - 1620s 754ms/step - loss: 1.4934 - mean_absolute_error: 0.8755 - val_loss: 3.5095 - val_mean_absolute_error: 1.6981\n",
            "Epoch 2/40\n",
            "2149/2149 [==============================] - 1613s 751ms/step - loss: 0.8364 - mean_absolute_error: 0.7257 - val_loss: 3.8304 - val_mean_absolute_error: 1.7826\n",
            "Epoch 3/40\n",
            "2149/2149 [==============================] - 1609s 749ms/step - loss: 0.7538 - mean_absolute_error: 0.6886 - val_loss: 3.7467 - val_mean_absolute_error: 1.7626\n",
            "Epoch 4/40\n",
            "2149/2149 [==============================] - 1605s 747ms/step - loss: 0.7403 - mean_absolute_error: 0.6833 - val_loss: 3.8650 - val_mean_absolute_error: 1.7935\n",
            "Epoch 5/40\n",
            "2149/2149 [==============================] - 1605s 747ms/step - loss: 0.7119 - mean_absolute_error: 0.6694 - val_loss: 3.9338 - val_mean_absolute_error: 1.8148\n",
            "Epoch 6/40\n",
            "2149/2149 [==============================] - 1602s 746ms/step - loss: 0.6838 - mean_absolute_error: 0.6548 - val_loss: 3.8971 - val_mean_absolute_error: 1.8119\n",
            "Epoch 7/40\n",
            "2149/2149 [==============================] - 1602s 746ms/step - loss: 0.6557 - mean_absolute_error: 0.6402 - val_loss: 3.9562 - val_mean_absolute_error: 1.8336\n",
            "Epoch 8/40\n",
            "2149/2149 [==============================] - 1597s 744ms/step - loss: 0.6270 - mean_absolute_error: 0.6237 - val_loss: 3.9678 - val_mean_absolute_error: 1.8411\n",
            "Epoch 9/40\n",
            "2149/2149 [==============================] - 1596s 743ms/step - loss: 0.5971 - mean_absolute_error: 0.6073 - val_loss: 3.8495 - val_mean_absolute_error: 1.8172\n",
            "Epoch 10/40\n",
            "2149/2149 [==============================] - 1596s 743ms/step - loss: 0.5651 - mean_absolute_error: 0.5886 - val_loss: 3.5607 - val_mean_absolute_error: 1.7467\n",
            "Epoch 11/40\n",
            "2149/2149 [==============================] - 1591s 741ms/step - loss: 0.5356 - mean_absolute_error: 0.5717 - val_loss: 3.0633 - val_mean_absolute_error: 1.6119\n",
            "Epoch 12/40\n",
            "2149/2149 [==============================] - 1591s 741ms/step - loss: 0.5060 - mean_absolute_error: 0.5531 - val_loss: 3.0009 - val_mean_absolute_error: 1.6020\n",
            "Epoch 13/40\n",
            "2149/2149 [==============================] - 1591s 741ms/step - loss: 0.4748 - mean_absolute_error: 0.5336 - val_loss: 2.9728 - val_mean_absolute_error: 1.6004\n",
            "Epoch 14/40\n",
            "2149/2149 [==============================] - 1589s 740ms/step - loss: 0.4466 - mean_absolute_error: 0.5146 - val_loss: 2.8919 - val_mean_absolute_error: 1.5826\n",
            "Epoch 15/40\n",
            "2149/2149 [==============================] - 1588s 739ms/step - loss: 0.4253 - mean_absolute_error: 0.5003 - val_loss: 3.0240 - val_mean_absolute_error: 1.6269\n",
            "Epoch 16/40\n",
            "2149/2149 [==============================] - 1587s 739ms/step - loss: 0.4050 - mean_absolute_error: 0.4877 - val_loss: 2.9849 - val_mean_absolute_error: 1.6176\n",
            "Epoch 17/40\n",
            "2149/2149 [==============================] - 1582s 736ms/step - loss: 0.3922 - mean_absolute_error: 0.4787 - val_loss: 2.9395 - val_mean_absolute_error: 1.6059\n",
            "Epoch 18/40\n",
            "2149/2149 [==============================] - 1578s 735ms/step - loss: 0.3979 - mean_absolute_error: 0.4834 - val_loss: 2.4549 - val_mean_absolute_error: 1.4521\n",
            "Epoch 19/40\n",
            "2149/2149 [==============================] - 1580s 736ms/step - loss: 0.4210 - mean_absolute_error: 0.5002 - val_loss: 2.6062 - val_mean_absolute_error: 1.4970\n",
            "Epoch 20/40\n",
            "2149/2149 [==============================] - 1577s 734ms/step - loss: 0.4262 - mean_absolute_error: 0.5037 - val_loss: 3.2207 - val_mean_absolute_error: 1.6841\n",
            "Epoch 21/40\n",
            "2149/2149 [==============================] - 1574s 733ms/step - loss: 0.4141 - mean_absolute_error: 0.4955 - val_loss: 3.2633 - val_mean_absolute_error: 1.6980\n",
            "Epoch 22/40\n",
            "2149/2149 [==============================] - 1572s 732ms/step - loss: 0.3753 - mean_absolute_error: 0.4676 - val_loss: 3.2247 - val_mean_absolute_error: 1.6934\n",
            "Epoch 23/40\n",
            "2149/2149 [==============================] - 1572s 732ms/step - loss: 0.3492 - mean_absolute_error: 0.4490 - val_loss: 3.3282 - val_mean_absolute_error: 1.7259\n",
            "Epoch 24/40\n",
            "2149/2149 [==============================] - 1568s 730ms/step - loss: 0.3496 - mean_absolute_error: 0.4495 - val_loss: 2.6916 - val_mean_absolute_error: 1.5337\n",
            "Epoch 25/40\n",
            "2149/2149 [==============================] - 1566s 729ms/step - loss: 0.3646 - mean_absolute_error: 0.4608 - val_loss: 2.6232 - val_mean_absolute_error: 1.5082\n",
            "Epoch 26/40\n",
            "2149/2149 [==============================] - 1562s 727ms/step - loss: 0.4059 - mean_absolute_error: 0.4896 - val_loss: 4.8498 - val_mean_absolute_error: 2.1091\n",
            "Epoch 27/40\n",
            "2149/2149 [==============================] - 1560s 726ms/step - loss: 0.4495 - mean_absolute_error: 0.5198 - val_loss: 3.5926 - val_mean_absolute_error: 1.7858\n",
            "Epoch 28/40\n",
            "2149/2149 [==============================] - 1558s 725ms/step - loss: 0.4048 - mean_absolute_error: 0.4892 - val_loss: 3.7760 - val_mean_absolute_error: 1.8450\n",
            "Epoch 29/40\n",
            "2149/2149 [==============================] - 1556s 724ms/step - loss: 0.3395 - mean_absolute_error: 0.4419 - val_loss: 3.0469 - val_mean_absolute_error: 1.6473\n",
            "Epoch 30/40\n",
            "2149/2149 [==============================] - 1556s 724ms/step - loss: 0.3231 - mean_absolute_error: 0.4308 - val_loss: 2.8788 - val_mean_absolute_error: 1.5980\n",
            "Epoch 31/40\n",
            "2149/2149 [==============================] - 1554s 723ms/step - loss: 0.3176 - mean_absolute_error: 0.4270 - val_loss: 2.8567 - val_mean_absolute_error: 1.5901\n",
            "Epoch 32/40\n",
            "2149/2149 [==============================] - 1556s 724ms/step - loss: 0.3314 - mean_absolute_error: 0.4371 - val_loss: 3.5423 - val_mean_absolute_error: 1.7846\n",
            "Epoch 33/40\n",
            "2149/2149 [==============================] - 1553s 723ms/step - loss: 0.3505 - mean_absolute_error: 0.4521 - val_loss: 3.6000 - val_mean_absolute_error: 1.8024\n",
            "Epoch 34/40\n",
            "2149/2149 [==============================] - 1552s 723ms/step - loss: 0.3590 - mean_absolute_error: 0.4587 - val_loss: 4.0461 - val_mean_absolute_error: 1.9203\n",
            "Epoch 35/40\n",
            "2149/2149 [==============================] - 1552s 722ms/step - loss: 0.3666 - mean_absolute_error: 0.4635 - val_loss: 4.4007 - val_mean_absolute_error: 2.0069\n",
            "Epoch 36/40\n",
            "2149/2149 [==============================] - 1549s 721ms/step - loss: 0.4132 - mean_absolute_error: 0.4970 - val_loss: 2.4040 - val_mean_absolute_error: 1.4292\n",
            "Epoch 37/40\n",
            "2149/2149 [==============================] - 1546s 720ms/step - loss: 0.4230 - mean_absolute_error: 0.5034 - val_loss: 2.4034 - val_mean_absolute_error: 1.4323\n",
            "Epoch 38/40\n",
            "2149/2149 [==============================] - 1546s 720ms/step - loss: 0.3516 - mean_absolute_error: 0.4515 - val_loss: 2.9242 - val_mean_absolute_error: 1.6100\n",
            "Epoch 39/40\n",
            "2149/2149 [==============================] - 1536s 715ms/step - loss: 0.3119 - mean_absolute_error: 0.4227 - val_loss: 3.7101 - val_mean_absolute_error: 1.8376\n",
            "Epoch 40/40\n",
            "2149/2149 [==============================] - 1536s 715ms/step - loss: 0.3063 - mean_absolute_error: 0.4188 - val_loss: 2.9887 - val_mean_absolute_error: 1.6324\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    elapsed time: 63025.4187 seconds\n"
          ]
        }
      ],
      "source": [
        "# epochs to run for\n",
        "epochs = 40\n",
        "\n",
        "# timer\n",
        "t = Timer()\n",
        "\n",
        "# current model\n",
        "model = augur_model()\n",
        "# fit the model, validate and plot results\n",
        "print(f'training model for {epochs}')\n",
        "t.start()\n",
        "mae, val_mae = run_model(model, train_ds, val_ds, epochs=epochs, start_epoch=1, oneshot=True, verbose=True)\n",
        "t.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f83b9275-b52b-4b61-a1e0-07f4ba8d8e0a",
      "metadata": {
        "id": "f83b9275-b52b-4b61-a1e0-07f4ba8d8e0a"
      },
      "outputs": [],
      "source": [
        "augur_mae = mae\n",
        "augur_val_mae = val_mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9ecdfb-61a4-4dd0-9089-15022d0b72c7",
      "metadata": {
        "id": "9d9ecdfb-61a4-4dd0-9089-15022d0b72c7",
        "outputId": "2c4a5e31-1a09-46df-ebd6-1e7728738aa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training final model model_full_augur.keras for 37 epochs\n",
            "  building model\n",
            "  training model\n",
            "    elapsed time: 66046.5175 seconds\n",
            "  evaluating model\n",
            "672/672 [==============================] - 100s 149ms/step - loss: 3.1555 - mean_absolute_error: 1.6659\n",
            "  mean absolute evaluation error is [3.1555373668670654, 1.6658642292022705]\n",
            "  saving model\n"
          ]
        }
      ],
      "source": [
        "# train final model\n",
        "\n",
        "# model file name\n",
        "model_name = nb_path + 'model_full_augur_colab.keras'\n",
        "\n",
        "# timer\n",
        "t = Timer()\n",
        "\n",
        "# number of epochs to train for\n",
        "epochs = 37\n",
        "\n",
        "print(f'training final model {model_name} for {epochs} epochs')\n",
        "\n",
        "print('  building model')\n",
        "model = augur_model()\n",
        "\n",
        "print('  training model')\n",
        "t.start()\n",
        "run_model(model, train_full_ds, None, epochs=epochs, start_epoch=1, oneshot=False, verbose=False)\n",
        "t.stop()\n",
        "\n",
        "print('  evaluating model')\n",
        "mae = model.evaluate(test_ds)\n",
        "print(f'  mean absolute evaluation error is {mae}')\n",
        "\n",
        "print('  saving model')\n",
        "model.save(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "96105e2c-933d-405b-98aa-6576e6e2c792",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "96105e2c-933d-405b-98aa-6576e6e2c792",
        "outputId": "388ae841-80e5-4405-b122-0ed4209ec8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training model for 40\n",
            "Model: \"FullModel\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " inputs_1 (InputLayer)       [(None, None, 10)]           0         []                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, None, 280)            33880     ['inputs_1[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, None, 280)            1120      ['conv1d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, None, 280)            0         ['batch_normalization[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, None, 280)            0         ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, None, 896)            2612736   ['dropout[0][0]']             \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPoolin  (None, None, 896)            0         ['bidirectional[0][0]']       \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 896)            0         ['max_pooling1d_1[0][0]']     \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 896)                  0         ['dropout_1[0][0]']           \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " inputs_2 (InputLayer)       [(None, 29)]                 0         []                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 925)                  0         ['global_max_pooling1d[0][0]',\n",
            "                                                                     'inputs_2[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  118528    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 128)                  512       ['dense[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 128)                  0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 1)                    129       ['dropout_2[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2766905 (10.55 MB)\n",
            "Trainable params: 2766089 (10.55 MB)\n",
            "Non-trainable params: 816 (3.19 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/40\n",
            "1784/2149 [=======================>......] - ETA: 37:33 - loss: 2.6797 - mean_absolute_error: 1.1379"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node gradient_tape/FullModel/max_pooling1d_1/MaxPool/MaxPoolGrad defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-28-df229a97a9e8>\", line 12, in <cell line: 12>\n\n  File \"<ipython-input-9-67506938dbd4>\", line 16, in run_model\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n\nOOM when allocating tensor with shape[64,896,2541,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/FullModel/max_pooling1d_1/MaxPool/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_394849]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-df229a97a9e8>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'training model for {epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moneshot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-67506938dbd4>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(model, train_ds, val_ds, epochs, start_epoch, oneshot, verbose)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBackupAndRestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackup_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/bar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node gradient_tape/FullModel/max_pooling1d_1/MaxPool/MaxPoolGrad defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-28-df229a97a9e8>\", line 12, in <cell line: 12>\n\n  File \"<ipython-input-9-67506938dbd4>\", line 16, in run_model\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1154, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 543, in minimize\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/optimizer.py\", line 276, in compute_gradients\n\nOOM when allocating tensor with shape[64,896,2541,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/FullModel/max_pooling1d_1/MaxPool/MaxPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_394849]"
          ]
        }
      ],
      "source": [
        "# epochs to run for\n",
        "epochs = 40\n",
        "\n",
        "# timer\n",
        "t = Timer()\n",
        "\n",
        "# current model\n",
        "model = dan_zrimec_model()\n",
        "# fit the model, validate and plot results\n",
        "print(f'training model for {epochs}')\n",
        "t.start()\n",
        "mae, val_mae = run_model(model, train_ds, val_ds, epochs=epochs, start_epoch=1, oneshot=True, verbose=True)\n",
        "t.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16378ed5-1e16-4ee2-a687-c461ec5474b1",
      "metadata": {
        "id": "16378ed5-1e16-4ee2-a687-c461ec5474b1"
      },
      "outputs": [],
      "source": [
        "dz_mae = mae\n",
        "dz_val_mae = val_mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3241db9d-874d-4404-bd59-087ab4edda50",
      "metadata": {
        "id": "3241db9d-874d-4404-bd59-087ab4edda50"
      },
      "outputs": [],
      "source": [
        "# train final model\n",
        "\n",
        "# model file name\n",
        "model_name = nb_path + 'model_full_dz_colab.keras'\n",
        "\n",
        "# timer\n",
        "t = Timer()\n",
        "\n",
        "# number of epochs to train for\n",
        "epochs = 37\n",
        "\n",
        "print(f'training final model {model_name} for {epochs} epochs')\n",
        "\n",
        "print('  building model')\n",
        "model = dan_zrimec_model()\n",
        "\n",
        "print('  training model')\n",
        "t.start()\n",
        "run_model(model, train_full_ds, None, epochs=epochs, start_epoch=1, oneshot=False, verbose=False)\n",
        "t.stop()\n",
        "\n",
        "print('  evaluating model')\n",
        "mae = model.evaluate(test_ds)\n",
        "print(f'  mean absolute evaluation error is {mae}')\n",
        "\n",
        "print('  saving model')\n",
        "model.save(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd15effe-0d99-4c4b-ab7d-261f42efa608",
      "metadata": {
        "id": "dd15effe-0d99-4c4b-ab7d-261f42efa608"
      },
      "source": [
        "## k-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b66d001b-11b1-4d6a-9dc0-90dc7a290af5",
      "metadata": {
        "id": "b66d001b-11b1-4d6a-9dc0-90dc7a290af5"
      },
      "outputs": [],
      "source": [
        "num_splits = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31421c42-2e54-40a6-be5e-720f33e4dd3d",
      "metadata": {
        "id": "31421c42-2e54-40a6-be5e-720f33e4dd3d"
      },
      "source": [
        "### Augur Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e139b274-5025-4118-a01f-2fb56657f7d5",
      "metadata": {
        "id": "e139b274-5025-4118-a01f-2fb56657f7d5"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# run k-fold cross validation\n",
        "\n",
        "# epochs to run for\n",
        "epochs = 100\n",
        "\n",
        "# timer\n",
        "t = Timer()\n",
        "\n",
        "# training and validation mean absolute error results\n",
        "train_mae = []\n",
        "val_mae = []\n",
        "\n",
        "print(f'k-fold cross validation with {num_splits} splits for {epochs} epochs')\n",
        "kf = KFold(n_splits=num_splits, shuffle=True, random_state=1202)\n",
        "for i, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
        "    print(f'  processing fold {i}')\n",
        "\n",
        "    # split the data\n",
        "    print('    splitting data')\n",
        "    t.start()\n",
        "    X_train_kf, X_val_kf, y_train_kf, y_val_kf = X_train[train_index], X_train[val_index], y_train[train_index], y_train[val_index]\n",
        "    t.stop()\n",
        "\n",
        "    # build the datasets\n",
        "    print('    creating training dataset')\n",
        "    t.start()\n",
        "    train_ds = create_dataset(X_train_kf, y_train_kf, batch_size=batch_size, sort=True)\n",
        "    t.stop()\n",
        "    print('    creating validation dataset')\n",
        "    t.start()\n",
        "    val_ds = create_dataset(X_val_kf, y_val_kf, batch_size=batch_size, sort=False)\n",
        "    t.stop()\n",
        "\n",
        "    # fit the model and return mae\n",
        "    print('    fitting model')\n",
        "    t.start()\n",
        "    t_mae, v_mae = run_model(augur_model(), train_ds, val_ds, epochs=epochs, start_epoch=1, oneshot=False, verbose=False)\n",
        "    t.stop()\n",
        "\n",
        "    # add returned mae values to the arrays\n",
        "    train_mae.append(t_mae)\n",
        "    val_mae.append(v_mae)\n",
        "\n",
        "# calculate the average\n",
        "average_train_mae = [ np.mean([ x[i] for x in train_mae ]) for i in range(epochs) ]\n",
        "average_val_mae = [ np.mean([ x[i] for x in val_mae ]) for i in range(epochs) ]\n",
        "\n",
        "# plot\n",
        "plot_loss(average_train_mae, average_val_mae, start_epoch=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c833d59-8d0b-4c09-8b27-32841e29e43d",
      "metadata": {
        "id": "7c833d59-8d0b-4c09-8b27-32841e29e43d"
      },
      "outputs": [],
      "source": [
        "# train final model\n",
        "\n",
        "# model file name\n",
        "model_name = 'model_augur.keras'\n",
        "\n",
        "# timer\n",
        "t = Timer()\n",
        "\n",
        "# training and validation mean absolute error results\n",
        "train_mae = []\n",
        "val_mae = []\n",
        "\n",
        "# number of epochs to train for\n",
        "epochs = 40\n",
        "\n",
        "print(f'training final model {model_name} for {epochs} epochs')\n",
        "\n",
        "print('  creating training dataset')\n",
        "t.start()\n",
        "train_ds = create_dataset(X_train, y_train, batch_size=batch_size, sort=True)\n",
        "t.stop()\n",
        "\n",
        "print('  building model')\n",
        "model = augur_model()\n",
        "\n",
        "print('  training model')\n",
        "t.start()\n",
        "run_model(model, train_ds, None, epochs=epochs, start_epoch=1, oneshot=False, verbose=False)\n",
        "t.stop()\n",
        "\n",
        "print('  evaluating model')\n",
        "mae = model.evaluate(test_ds)\n",
        "print(f'  mean absolute evaluation error is {mae}')\n",
        "\n",
        "print('  saving model')\n",
        "model.save(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e83109b-8577-4591-945e-c2d08491d1a8",
      "metadata": {
        "id": "5e83109b-8577-4591-945e-c2d08491d1a8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# run k-fold cross validation\n",
        "\n",
        "# epochs to run for\n",
        "epochs = 100\n",
        "\n",
        "# timer\n",
        "t = Timer()\n",
        "\n",
        "# training and validation mean absolute error results\n",
        "train_mae = []\n",
        "val_mae = []\n",
        "\n",
        "print(f'k-fold cross validation with {num_splits} splits for {epochs} epochs')\n",
        "kf = KFold(n_splits=num_splits, shuffle=True, random_state=1202)\n",
        "for i, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
        "    print(f'  processing fold {i}')\n",
        "\n",
        "    # split the data\n",
        "    print('    splitting data')\n",
        "    t.start()\n",
        "    X_train_kf, X_val_kf, y_train_kf, y_val_kf = X_train[train_index], X_train[val_index], y_train[train_index], y_train[val_index]\n",
        "    t.stop()\n",
        "\n",
        "    # build the datasets\n",
        "    print('    creating training dataset')\n",
        "    t.start()\n",
        "    train_ds = create_dataset(X_train_kf, y_train_kf, batch_size=batch_size, sort=True)\n",
        "    t.stop()\n",
        "    print('    creating validation dataset')\n",
        "    t.start()\n",
        "    val_ds = create_dataset(X_val_kf, y_val_kf, batch_size=batch_size, sort=False)\n",
        "    t.stop()\n",
        "\n",
        "    # fit the model and return mae\n",
        "    print('    fitting model')\n",
        "    t.start()\n",
        "    t_mae, v_mae = run_model(dan_zrimec_model(), train_ds, val_ds, epochs=epochs, start_epoch=1, oneshot=False, verbose=False)\n",
        "    t.stop()\n",
        "\n",
        "    # add returned mae values to the arrays\n",
        "    train_mae.append(t_mae)\n",
        "    val_mae.append(v_mae)\n",
        "\n",
        "# calculate the average\n",
        "average_train_mae = [ np.mean([ x[i] for x in train_mae ]) for i in range(epochs) ]\n",
        "average_val_mae = [ np.mean([ x[i] for x in val_mae ]) for i in range(epochs) ]\n",
        "\n",
        "# plot\n",
        "plot_loss(average_train_mae, average_val_mae, start_epoch=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77c94735-fe6c-46bc-815d-ef0a7f6def94",
      "metadata": {
        "id": "77c94735-fe6c-46bc-815d-ef0a7f6def94"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# run k-fold cross validation\n",
        "\n",
        "# epochs to run for\n",
        "epochs = 100\n",
        "\n",
        "# timer\n",
        "t = Timer()\n",
        "\n",
        "# training and validation mean absolute error results\n",
        "train_mae = []\n",
        "val_mae = []\n",
        "\n",
        "print(f'k-fold cross validation with {num_splits} splits for {epochs} epochs')\n",
        "kf = KFold(n_splits=num_splits, shuffle=True, random_state=1202)\n",
        "for i, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
        "    print(f'  processing fold {i}')\n",
        "\n",
        "    # split the data\n",
        "    print('    splitting data')\n",
        "    t.start()\n",
        "    X_train_kf, X_val_kf, y_train_kf, y_val_kf = X_train[train_index], X_train[val_index], y_train[train_index], y_train[val_index]\n",
        "    t.stop()\n",
        "\n",
        "    # build the datasets\n",
        "    print('    creating training dataset')\n",
        "    t.start()\n",
        "    train_ds = create_dataset(X_train_kf, y_train_kf, batch_size=batch_size, sort=True)\n",
        "    t.stop()\n",
        "    print('    creating validation dataset')\n",
        "    t.start()\n",
        "    val_ds = create_dataset(X_val_kf, y_val_kf, batch_size=batch_size, sort=False)\n",
        "    t.stop()\n",
        "\n",
        "    # fit the model and return mae\n",
        "    print('    fitting model')\n",
        "    t.start()\n",
        "    t_mae, v_mae = run_model(dan_zrimec_model2(), train_ds, val_ds, epochs=epochs, start_epoch=1, oneshot=False, verbose=False)\n",
        "    t.stop()\n",
        "\n",
        "    # add returned mae values to the arrays\n",
        "    train_mae.append(t_mae)\n",
        "    val_mae.append(v_mae)\n",
        "\n",
        "# calculate the average\n",
        "average_train_mae = [ np.mean([ x[i] for x in train_mae ]) for i in range(epochs) ]\n",
        "average_val_mae = [ np.mean([ x[i] for x in val_mae ]) for i in range(epochs) ]\n",
        "\n",
        "# plot\n",
        "plot_loss(average_train_mae, average_val_mae, start_epoch=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff8053c0-8c5f-4da9-9217-d8bb8a1433b6",
      "metadata": {
        "id": "ff8053c0-8c5f-4da9-9217-d8bb8a1433b6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "181cfeca-7bde-4da8-aa66-3e4379026cd5",
      "metadata": {
        "id": "181cfeca-7bde-4da8-aa66-3e4379026cd5"
      },
      "source": [
        "# what are the steps?\n",
        "\n",
        "- create ragged tensor from X_test\n",
        "- create dataset from X_test and y_test\n",
        "\n",
        "k-fold cross validation for the baseline neural network\n",
        "- input is X_train, y_train\n",
        "- using KFold this will be split in k folds\n",
        "  - sort the trainin part\n",
        "  - convert X to ragged tensor\n",
        "  - create dataset\n",
        "  - train\n",
        "  - evaluate\n",
        "- evaluate the cross fold performance\n",
        "- rerun model with the whole dataset (test+val)\n",
        "- save the model\n",
        "```\n",
        "kf = KFold(n_splits=num_splits, shuffle=True, random_state=1202)\n",
        "for i, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
        "    print(f\"Fold {i}:\")\n",
        "    X_train_kf, X_test_kf, y_train_kf, y_test_kf = X_train[train_index], X_train[test_index], y_train[train_index], y_train[test_index]\n",
        "    # sort X_train_kf and y_train_kf\n",
        "    # convert X_train_kf to ragged tensor\n",
        "    # create dataset from X_train_kf and y_train_kf\n",
        "    # do the training and evaluation\n",
        "# evaluate the cross fold performance\n",
        "```\n",
        "\n",
        "train/val split for the full neural network -> separate jupyter notebook\n",
        "- input X_train, y_train\n",
        "- split the training test set again in train and val\n",
        "- create ragged tensor from training X\n",
        "- create dataset from training X and y\n",
        "- train\n",
        "- evaluate\n",
        "- rerun the model with the whole dataset (test+val)\n",
        "- save the model\n",
        "\n",
        "\n",
        "what have both in common?\n",
        "- data load and initial prep (up to the first split)\n",
        "- model setup\n",
        "- training setup\n",
        "- visualisation\n",
        "- evaluation -> this is just one command\n",
        "\n",
        "helpful methods\n",
        "- create_dataset(X, y, sort=False)\n",
        "  input X and y, specify if the dataset should be sorted\n",
        "  returns a TF dataset\n",
        "- run_model(model, epochs, plot=True, plot_epoch_start=0)\n",
        "- plot_loss()\n",
        "\n",
        "- callbacks\n",
        "    - earlystopping -> to limit training that doesn't progress, only for the tuner\n",
        "    - backupandrestore -> for the full training as fault tolerance setup\n",
        "    - modelcheckpoint -> to save the best model on the final train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcbc7e7c-4981-4ce5-9435-b20fea7cd399",
      "metadata": {
        "id": "bcbc7e7c-4981-4ce5-9435-b20fea7cd399"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45b8d99d-4c8c-4af2-b9ce-77df859362a3",
      "metadata": {
        "id": "45b8d99d-4c8c-4af2-b9ce-77df859362a3"
      },
      "outputs": [],
      "source": [
        "# split the train set again in train and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1202)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c86b943-3471-42b6-bef0-e60a0e376568",
      "metadata": {
        "id": "6c86b943-3471-42b6-bef0-e60a0e376568"
      },
      "outputs": [],
      "source": [
        "# find the first unique PTR value that is also in y_train\n",
        "train_idx = 0\n",
        "for i in range(len(y)):\n",
        "    count = 0\n",
        "    for l in range(len(y)):\n",
        "        if i != l and y[i] == y[l]:\n",
        "            count += 1\n",
        "            continue\n",
        "    if count == 0:\n",
        "        for m in range(len(y_train)):\n",
        "            if y[i] == y_train[m]:\n",
        "                train_idx = m\n",
        "                break\n",
        "train_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "387f1c55-480e-459b-b295-ddc038493283",
      "metadata": {
        "id": "387f1c55-480e-459b-b295-ddc038493283"
      },
      "outputs": [],
      "source": [
        "# get a sample\n",
        "X_train[train_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82384079-68d4-4ca6-9301-b856d56aeb4d",
      "metadata": {
        "id": "82384079-68d4-4ca6-9301-b856d56aeb4d"
      },
      "outputs": [],
      "source": [
        "# get the matching target\n",
        "search_y = y_train[train_idx]\n",
        "search_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737386f4-6bdc-446b-8f31-a910f9f015c7",
      "metadata": {
        "id": "737386f4-6bdc-446b-8f31-a910f9f015c7"
      },
      "outputs": [],
      "source": [
        "# find the target value in the raw dataset\n",
        "full_idx = 0\n",
        "for i in range(len(y)):\n",
        "    if y[i] == search_y:\n",
        "        print(i)\n",
        "        full_idx = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29af14a0-e1a3-45ab-8d0b-56dc0020917b",
      "metadata": {
        "id": "29af14a0-e1a3-45ab-8d0b-56dc0020917b"
      },
      "outputs": [],
      "source": [
        "# compare if the raw dataset entry matches the subset entry\n",
        "if X[full_idx].all() == X_train[train_idx].all():\n",
        "    print('OK')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4f525a1-3fef-4b27-b7ee-eb136ff06ebc",
      "metadata": {
        "id": "f4f525a1-3fef-4b27-b7ee-eb136ff06ebc"
      },
      "source": [
        "### Sort Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94fc569c-9d02-4619-82bf-ebf4e4caaf49",
      "metadata": {
        "id": "94fc569c-9d02-4619-82bf-ebf4e4caaf49"
      },
      "outputs": [],
      "source": [
        "# build an inhomogenous numpy array from the training set\n",
        "X_train = np.array(X_train, dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc1d8b7-225a-43b4-a3a7-344569269d8a",
      "metadata": {
        "id": "bbc1d8b7-225a-43b4-a3a7-344569269d8a"
      },
      "outputs": [],
      "source": [
        "# build an array containing the sequence lengths\n",
        "sequence_lengths = list(map(lambda x: len(x), X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5360be4d-b70c-4fe6-9515-a0b904e0fa3d",
      "metadata": {
        "id": "5360be4d-b70c-4fe6-9515-a0b904e0fa3d"
      },
      "outputs": [],
      "source": [
        "# sort the array but only get the indices\n",
        "sorted_indices = np.argsort(sequence_lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0200e456-a746-417d-bc9c-ca4f75fa973b",
      "metadata": {
        "id": "0200e456-a746-417d-bc9c-ca4f75fa973b"
      },
      "outputs": [],
      "source": [
        "sorted_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75abd9cc-7c09-40b0-b5a0-619bfc2e5a6b",
      "metadata": {
        "id": "75abd9cc-7c09-40b0-b5a0-619bfc2e5a6b"
      },
      "outputs": [],
      "source": [
        "# now sort the X and y train arrays according to the sorted indicds\n",
        "X_train = X_train[sorted_indices]\n",
        "y_train = y_train[sorted_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9070a40-d333-4008-9a8b-edb277a5209c",
      "metadata": {
        "id": "d9070a40-d333-4008-9a8b-edb277a5209c"
      },
      "outputs": [],
      "source": [
        "# check if the previously found values still correlate\n",
        "for i in range(len(y_train)):\n",
        "    if y_train[i] == search_y:\n",
        "        print(X_train[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48e10faa-ea20-42bb-bd97-75395da099c9",
      "metadata": {
        "id": "48e10faa-ea20-42bb-bd97-75395da099c9"
      },
      "source": [
        "### Ragged Tensor Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b86fae6d-0aa3-4bb5-97ec-e2e8920e1b23",
      "metadata": {
        "id": "b86fae6d-0aa3-4bb5-97ec-e2e8920e1b23"
      },
      "outputs": [],
      "source": [
        "# this does not work since the sequences are of different length\n",
        "# X_test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d39e886-2279-4bbb-a838-c44e26ba3ef6",
      "metadata": {
        "id": "3d39e886-2279-4bbb-a838-c44e26ba3ef6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "X_train_tensor = tf.ragged.constant(X_train, dtype=tf.int8, ragged_rank=1, row_splits_dtype=tf.int32)\n",
        "X_val_tensor = tf.ragged.constant(X_val, dtype=tf.int8, ragged_rank=1, row_splits_dtype=tf.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850a17ad-bb52-4365-9424-3447b37529ab",
      "metadata": {
        "id": "850a17ad-bb52-4365-9424-3447b37529ab"
      },
      "outputs": [],
      "source": [
        "X_train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train))\n",
        "X_val_dataset = tf.data.Dataset.from_tensor_slices((X_val_tensor, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c506f768-6e15-4c6f-872b-0038d177dd57",
      "metadata": {
        "id": "c506f768-6e15-4c6f-872b-0038d177dd57"
      },
      "outputs": [],
      "source": [
        "X_train_dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "907d3def-dbf3-4830-aad6-5368d664e235",
      "metadata": {
        "id": "907d3def-dbf3-4830-aad6-5368d664e235"
      },
      "outputs": [],
      "source": [
        "X_val_dataset.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a705eb41-faff-44f3-b262-88b883ec013a",
      "metadata": {
        "id": "a705eb41-faff-44f3-b262-88b883ec013a"
      },
      "outputs": [],
      "source": [
        "# padded batches from ragged tensors are not supported (yet)\n",
        "# it needs a work around creating a uniform tensor\n",
        "# idea from : https://github.com/tensorflow/tensorflow/issues/39163\n",
        "def reformat(data, label):\n",
        "    return data, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "805f9521-15da-4791-9a6a-5cf3dca18a31",
      "metadata": {
        "id": "805f9521-15da-4791-9a6a-5cf3dca18a31"
      },
      "outputs": [],
      "source": [
        "X_train_dataset = X_train_dataset.map(reformat)\n",
        "X_val_dataset = X_val_dataset.map(reformat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e6e1c8a-efb9-455b-a3b3-cabc2d02daa3",
      "metadata": {
        "id": "8e6e1c8a-efb9-455b-a3b3-cabc2d02daa3"
      },
      "outputs": [],
      "source": [
        "# shuffle the dataset (again) and create padded batches\n",
        "batch_size = 64\n",
        "X_train_dataset = X_train_dataset.padded_batch(batch_size)\n",
        "X_val_dataset = X_val_dataset.shuffle(buffer_size=len(X_val), seed=1202).padded_batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b2fa149-8b00-4210-8a33-2a3b810cbd49",
      "metadata": {
        "id": "2b2fa149-8b00-4210-8a33-2a3b810cbd49"
      },
      "outputs": [],
      "source": [
        "# optinally repeat the dataset multiple times -> WHY?\n",
        "# rep = 3\n",
        "# X_train_dataset = X_train_dataset.repeat(rep)\n",
        "# X_val_dataset = X_val_dataset.repeat(rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49244b0a-a161-457b-88d2-ba4417d89110",
      "metadata": {
        "id": "49244b0a-a161-457b-88d2-ba4417d89110"
      },
      "outputs": [],
      "source": [
        "datalen = []\n",
        "ds_iterator = iter(X_train_dataset)\n",
        "for data, label in ds_iterator:\n",
        "    datalen.append(len(data[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa0eb29-ea9c-4272-8cf9-682c9fe01451",
      "metadata": {
        "id": "6fa0eb29-ea9c-4272-8cf9-682c9fe01451"
      },
      "outputs": [],
      "source": [
        "datalen[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ba5416-4ed2-4d5f-8123-5e67e46b4dd5",
      "metadata": {
        "id": "f5ba5416-4ed2-4d5f-8123-5e67e46b4dd5"
      },
      "outputs": [],
      "source": [
        "# testing if keras can use the dataset\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(16, activation='relu', input_shape=(None,4)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.fit(X_train_dataset, epochs=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}