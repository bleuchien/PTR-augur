{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e465583-fc98-4fda-937a-475748037b12",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "*fancy introduction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f12e085-6ce6-41e0-8f1e-1d35b23bf358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 00:02:54.979534: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-16 00:02:55.256617: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-16 00:02:56.152068: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-16 00:02:56.152124: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-16 00:02:56.293311: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-16 00:02:56.688747: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-16 00:02:56.689589: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-16 00:03:00.835674: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# library dependencies\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import lzma\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff0f512-caac-4cb6-b469-b2bbd23ad3f9",
   "metadata": {},
   "source": [
    "The following methods read the prepared data files from the pre processing step and return the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ecd0a7-8f25-4b5b-bfb0-b5375b32c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to store data as serialized binary structure lzma compressed\n",
    "def can_pickles(data, filename):\n",
    "    with lzma.LZMAFile(filename, 'wb') as f:\n",
    "        pickle.dump(data, f, pickle.DEFAULT_PROTOCOL)\n",
    "\n",
    "# method to retrieve data from a compressed pickle file (created with the method above)\n",
    "def uncan_pickles(filename):\n",
    "    with lzma.LZMAFile(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330afba-bf62-4e92-ad84-62921e42d31f",
   "metadata": {},
   "source": [
    "## Basic Neural Network\n",
    "\n",
    "*explain it in more detail*\n",
    "\n",
    "X holds a list of sequences one hot encoded\n",
    "\n",
    "y holds a list of PTR values as floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d1d16d-426c-460f-930d-0e91adba9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the prepared data back\n",
    "X = uncan_pickles('../data/onehot_x_lung.pickle.xz')\n",
    "y = uncan_pickles('../data/onehot_y_lung.pickle.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e91af-1782-4909-8191-87442cac791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad add sequence entries to the same length\n",
    "# done here for simplicity to find a good neural network\n",
    "# X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3603897-eca1-41be-a833-79e59f4b5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert type of target values from string to float\n",
    "y = np.array(y).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85086f0d-2d79-4ee8-900d-cad1873c1b64",
   "metadata": {},
   "source": [
    "Random sample from X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41525e09-813f-46b8-9f47-ebbd7381510c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85471826-2b3a-4371-8441-ae940ba8e580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694f3792-6d06-48e0-81af-f689cbb35c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8201"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of input sequences\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab69104-daa6-4989-89aa-2f6a71f34b0b",
   "metadata": {},
   "source": [
    "### Baseline PTR\n",
    "\n",
    "There is no common sense approach in finding a baseline for the protein-to-mRNA ratio of a particular mRNA sequence. This is what the *Basic Neural Network* approach is for - to determin a baseline and see if a slightly adapted neural network with feature engineered input can provide better predictions.\n",
    "\n",
    "But what can be done is to simply check the value range of the target PTRs, calculate mean and standard deviation. Given that the standard deviation is  small (12.5% of the value range) one can (stupidly) predict the mean value every time. From that it's possible to calculate the Mean Absolute Error (MAE) and compare that to the following neural network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bfa09b2-b288-4618-88a6-7799e1335da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.552 8.587 4.973957444214121 0.8835629329175175\n"
     ]
    }
   ],
   "source": [
    "# get some idea of the range of the PTR in the selected SAMPLE\n",
    "print(np.min(y), np.max(y), np.mean(y), np.std(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9ba3da-9ab0-43f5-a923-63e94c580a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7055145713937325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple/dumb baseline mean absolute error of always predicting 4.974\n",
    "mae = np.mean(np.abs(np.array(y) - 4.974))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94586678-d302-4884-895d-d166c7e6f933",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Split data in train and test subsets and then split the train subset again in train and validation.\n",
    "\n",
    "A simple verification if the X and y correlation are preserved on the split is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "271ef8f9-7f36-4c73-a448-5abbf294bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in train and test sub sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41e1f188-4807-406d-b498-57b5589e6187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad test input (variable input is not accepted)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b64b18-bbd8-4d4e-b6db-30d063c7eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train set again in train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39872e7f-c57d-4122-b0ea-3dbb7b24763d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the first unique PTR value that is also in y_train\n",
    "train_idx = 0\n",
    "for i in range(len(y)):\n",
    "    count = 0\n",
    "    for l in range(len(y)):\n",
    "        if i != l and y[i] == y[l]:\n",
    "            count += 1\n",
    "            continue\n",
    "    if count == 0:\n",
    "        for m in range(len(y_train)):\n",
    "            if y[i] == y_train[m]:\n",
    "                train_idx = m\n",
    "                break\n",
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ad195bb-8171-4ed0-a232-b561d0942a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a sample\n",
    "X_train[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa42f36-5ebf-4541-9c2c-ecc7dece6446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.377"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the matching target\n",
    "search_y = y_train[train_idx]\n",
    "search_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7175df2-2e75-4fcd-8d66-6adf3f470b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8194\n"
     ]
    }
   ],
   "source": [
    "# find the target value in the raw dataset\n",
    "full_idx = 0\n",
    "for i in range(len(y)):\n",
    "    if y[i] == search_y:\n",
    "        print(i)\n",
    "        full_idx = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9857baf8-466f-4316-8335-e23a69b1c5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# compare if the raw dataset entry matches the subset entry\n",
    "if X[full_idx].all() == X_train[train_idx].all():\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37bd9c-8751-438c-a09a-633a050d5ee7",
   "metadata": {},
   "source": [
    "### Sort Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ce734dc-d388-4eaa-89e2-9ff29f0ff59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an inhomogenous numpy array from the training set\n",
    "X_train = np.array(X_train, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "202e05e3-0b6e-40ec-93f0-ab5bb51b3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an array containing the sequence lengths\n",
    "sequence_lengths = list(map(lambda x: len(x), X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c1bf6e-6f11-4bb3-b6c7-a113e31f360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the array but only get the indices\n",
    "sorted_indices = np.argsort(sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72c9666d-018e-4338-a7cd-c6ac0e3fdabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1140,  657, 1659, ...,   71, 4128, 5096])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5236ee90-c6bd-4483-9328-09c28bfa3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now sort the X and y train arrays according to the sorted indicds\n",
    "X_train = X_train[sorted_indices]\n",
    "y_train = y_train[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5ded927-98ca-40e1-b7e1-779ad6c5c25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# check if the previously found values still correlate\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == search_y:\n",
    "        print(X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e51d5a-aaf5-4507-be4c-9d44d06a457d",
   "metadata": {},
   "source": [
    "### Ragged Tensor Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218654e-0434-4ae2-8472-93003397a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does not work since the sequences are of different length\n",
    "# X_test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "169ae758-42e2-4f8b-9d32-7d64f8322c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 7s, sys: 50.1 s, total: 6min 57s\n",
      "Wall time: 6min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_tensor = tf.ragged.constant(X_train, dtype=tf.int8, ragged_rank=1, row_splits_dtype=tf.int32)\n",
    "X_val_tensor = tf.ragged.constant(X_val, dtype=tf.int8, ragged_rank=1, row_splits_dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8348ae2-0d05-4bf3-b64d-898eb5a9ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train))\n",
    "X_val_dataset = tf.data.Dataset.from_tensor_slices((X_val_tensor, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15d3004d-f438-48c2-b079-22fc282122e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RaggedTensorSpec(TensorShape([None, 4]), tf.int8, 0, tf.int32),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf34f643-79a9-469b-9353-7f60950f09f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RaggedTensorSpec(TensorShape([None, 4]), tf.int8, 0, tf.int32),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8502042d-58f5-4538-8578-e403365e1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded batches from ragged tensors are not supported (yet)\n",
    "# it needs a work around creating a uniform tensor\n",
    "# idea from : https://github.com/tensorflow/tensorflow/issues/39163\n",
    "def reformat(data, label):\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc3c4a63-47db-4263-a288-5969b7dbb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dataset = X_train_dataset.map(reformat)\n",
    "X_val_dataset = X_val_dataset.map(reformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c70893c0-2060-4ae7-9e2a-0cdbeb97921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataset (again) and create padded batches\n",
    "batch_size = 64\n",
    "X_train_dataset = X_train_dataset.padded_batch(batch_size)\n",
    "X_val_dataset = X_val_dataset.shuffle(buffer_size=len(X_val), seed=1202).padded_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be515ae3-b63a-4282-a614-d550e9d5369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optinally repeat the dataset multiple times -> WHY?\n",
    "# rep = 3\n",
    "# X_train_dataset = X_train_dataset.repeat(rep)\n",
    "# X_val_dataset = X_val_dataset.repeat(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00b046a1-22d0-42a9-94c0-7288e217425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalen = []\n",
    "ds_iterator = iter(X_train_dataset)\n",
    "for data, label in ds_iterator:\n",
    "    datalen.append(len(data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fbf6d94-f7c8-4613-8834-036bdd4d0190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[579, 679, 758, 857, 920]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalen[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14065709-7726-4aea-9188-83f593189fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 2s 16ms/step - loss: 20.0750 - mae: 4.3142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f6542e9e490>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing if keras can use the dataset\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(None,4)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit(X_train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a605e2-7641-40ae-91bb-3aa922bf7643",
   "metadata": {},
   "source": [
    "## Layer, Model and Prediction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe7debc6-1868-4b2a-8d44-f414532051bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Test\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, None, 4)]         0         \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, None, 32)          1312      \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, None, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, None, 32)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_17 (G  (None, 32)                0         \n",
      " lobalMaxPooling1D)                                              \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2529 (9.88 KB)\n",
      "Trainable params: 2465 (9.63 KB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 1.0532 - mean_absolute_error: 0.8134 - val_loss: 17.6425 - val_mean_absolute_error: 4.1085\n",
      "Epoch 2/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 1.0390 - mean_absolute_error: 0.8079 - val_loss: 14.0014 - val_mean_absolute_error: 3.6385\n",
      "Epoch 3/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.9025 - mean_absolute_error: 0.7553 - val_loss: 10.4679 - val_mean_absolute_error: 3.1153\n",
      "Epoch 4/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.8764 - mean_absolute_error: 0.7431 - val_loss: 6.9524 - val_mean_absolute_error: 2.4904\n",
      "Epoch 5/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.8383 - mean_absolute_error: 0.7277 - val_loss: 4.5728 - val_mean_absolute_error: 1.9662\n",
      "Epoch 6/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.8242 - mean_absolute_error: 0.7192 - val_loss: 3.2914 - val_mean_absolute_error: 1.6254\n",
      "Epoch 7/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.8241 - mean_absolute_error: 0.7213 - val_loss: 2.6014 - val_mean_absolute_error: 1.4184\n",
      "Epoch 8/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.8102 - mean_absolute_error: 0.7128 - val_loss: 2.2740 - val_mean_absolute_error: 1.3125\n",
      "Epoch 9/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7973 - mean_absolute_error: 0.7093 - val_loss: 2.1764 - val_mean_absolute_error: 1.2791\n",
      "Epoch 10/50\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 0.7965 - mean_absolute_error: 0.7089 - val_loss: 2.1741 - val_mean_absolute_error: 1.2795\n",
      "Epoch 11/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7902 - mean_absolute_error: 0.7064 - val_loss: 2.1363 - val_mean_absolute_error: 1.2657\n",
      "Epoch 12/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7866 - mean_absolute_error: 0.7056 - val_loss: 2.1545 - val_mean_absolute_error: 1.2719\n",
      "Epoch 13/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7833 - mean_absolute_error: 0.7032 - val_loss: 2.1663 - val_mean_absolute_error: 1.2759\n",
      "Epoch 14/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7809 - mean_absolute_error: 0.7042 - val_loss: 2.2178 - val_mean_absolute_error: 1.2933\n",
      "Epoch 15/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7812 - mean_absolute_error: 0.7022 - val_loss: 2.1403 - val_mean_absolute_error: 1.2675\n",
      "Epoch 16/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7711 - mean_absolute_error: 0.6978 - val_loss: 2.1749 - val_mean_absolute_error: 1.2797\n",
      "Epoch 17/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7765 - mean_absolute_error: 0.7003 - val_loss: 2.2198 - val_mean_absolute_error: 1.2954\n",
      "Epoch 18/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7664 - mean_absolute_error: 0.6966 - val_loss: 2.2714 - val_mean_absolute_error: 1.3122\n",
      "Epoch 19/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7636 - mean_absolute_error: 0.6943 - val_loss: 2.2311 - val_mean_absolute_error: 1.2991\n",
      "Epoch 20/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7580 - mean_absolute_error: 0.6907 - val_loss: 2.2655 - val_mean_absolute_error: 1.3113\n",
      "Epoch 21/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7581 - mean_absolute_error: 0.6919 - val_loss: 2.2881 - val_mean_absolute_error: 1.3192\n",
      "Epoch 22/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7550 - mean_absolute_error: 0.6902 - val_loss: 2.2620 - val_mean_absolute_error: 1.3116\n",
      "Epoch 23/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7493 - mean_absolute_error: 0.6877 - val_loss: 2.2960 - val_mean_absolute_error: 1.3234\n",
      "Epoch 24/50\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 0.7547 - mean_absolute_error: 0.6901 - val_loss: 2.2705 - val_mean_absolute_error: 1.3150\n",
      "Epoch 25/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7466 - mean_absolute_error: 0.6857 - val_loss: 2.2541 - val_mean_absolute_error: 1.3096\n",
      "Epoch 26/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7358 - mean_absolute_error: 0.6823 - val_loss: 2.3111 - val_mean_absolute_error: 1.3287\n",
      "Epoch 27/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7433 - mean_absolute_error: 0.6845 - val_loss: 2.3040 - val_mean_absolute_error: 1.3261\n",
      "Epoch 28/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7397 - mean_absolute_error: 0.6836 - val_loss: 2.2676 - val_mean_absolute_error: 1.3149\n",
      "Epoch 29/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7379 - mean_absolute_error: 0.6835 - val_loss: 2.2947 - val_mean_absolute_error: 1.3241\n",
      "Epoch 30/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7283 - mean_absolute_error: 0.6779 - val_loss: 2.3019 - val_mean_absolute_error: 1.3257\n",
      "Epoch 31/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7216 - mean_absolute_error: 0.6735 - val_loss: 2.2516 - val_mean_absolute_error: 1.3095\n",
      "Epoch 32/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7312 - mean_absolute_error: 0.6790 - val_loss: 2.2575 - val_mean_absolute_error: 1.3110\n",
      "Epoch 33/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7223 - mean_absolute_error: 0.6751 - val_loss: 2.3228 - val_mean_absolute_error: 1.3339\n",
      "Epoch 34/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7280 - mean_absolute_error: 0.6771 - val_loss: 2.2223 - val_mean_absolute_error: 1.2999\n",
      "Epoch 35/50\n",
      "82/82 [==============================] - 2s 22ms/step - loss: 0.7204 - mean_absolute_error: 0.6743 - val_loss: 2.2494 - val_mean_absolute_error: 1.3102\n",
      "Epoch 36/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7209 - mean_absolute_error: 0.6734 - val_loss: 2.2391 - val_mean_absolute_error: 1.3068\n",
      "Epoch 37/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7185 - mean_absolute_error: 0.6727 - val_loss: 2.2408 - val_mean_absolute_error: 1.3082\n",
      "Epoch 38/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7226 - mean_absolute_error: 0.6740 - val_loss: 2.2205 - val_mean_absolute_error: 1.3013\n",
      "Epoch 39/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7228 - mean_absolute_error: 0.6743 - val_loss: 2.2138 - val_mean_absolute_error: 1.2997\n",
      "Epoch 40/50\n",
      "82/82 [==============================] - 2s 25ms/step - loss: 0.7148 - mean_absolute_error: 0.6712 - val_loss: 2.2413 - val_mean_absolute_error: 1.3073\n",
      "Epoch 41/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7085 - mean_absolute_error: 0.6659 - val_loss: 2.2303 - val_mean_absolute_error: 1.3044\n",
      "Epoch 42/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7148 - mean_absolute_error: 0.6718 - val_loss: 2.1801 - val_mean_absolute_error: 1.2884\n",
      "Epoch 43/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7136 - mean_absolute_error: 0.6706 - val_loss: 2.1646 - val_mean_absolute_error: 1.2832\n",
      "Epoch 44/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7041 - mean_absolute_error: 0.6653 - val_loss: 2.2168 - val_mean_absolute_error: 1.3003\n",
      "Epoch 45/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7065 - mean_absolute_error: 0.6661 - val_loss: 2.2246 - val_mean_absolute_error: 1.3024\n",
      "Epoch 46/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7000 - mean_absolute_error: 0.6620 - val_loss: 2.2400 - val_mean_absolute_error: 1.3077\n",
      "Epoch 47/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7039 - mean_absolute_error: 0.6658 - val_loss: 2.1986 - val_mean_absolute_error: 1.2935\n",
      "Epoch 48/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.6997 - mean_absolute_error: 0.6631 - val_loss: 2.2168 - val_mean_absolute_error: 1.3003\n",
      "Epoch 49/50\n",
      "82/82 [==============================] - 2s 23ms/step - loss: 0.7036 - mean_absolute_error: 0.6653 - val_loss: 2.1887 - val_mean_absolute_error: 1.2898\n",
      "Epoch 50/50\n",
      "82/82 [==============================] - 2s 24ms/step - loss: 0.7028 - mean_absolute_error: 0.6618 - val_loss: 2.2151 - val_mean_absolute_error: 1.2984\n",
      "52/52 [==============================] - 0s 3ms/step\n",
      "Random prediction sample (truth, prediction): 4.92 [3.787206]\n",
      "52/52 [==============================] - 0s 342us/step - loss: 0.0000e+00 - mean_absolute_error: 0.0000e+00\n",
      "[0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(None, 4))\n",
    "conv1 = layers.Conv1D(\n",
    "    filters=32,\n",
    "    kernel_size=10,\n",
    "    strides=1,\n",
    "    activation='relu',\n",
    "    padding='valid'\n",
    ")(inputs)\n",
    "norm1 = layers.BatchNormalization()(conv1)\n",
    "drop1 = layers.Dropout(\n",
    "    rate=0.25\n",
    ")(norm1)\n",
    "# pool1 = layers.MaxPooling1D(\n",
    "#     pool_size=4,\n",
    "#     strides=4\n",
    "# )(drop1)\n",
    "pool1 = layers.GlobalMaxPool1D()(drop1)\n",
    "# flat = layers.Flatten()(drop1)\n",
    "dense = layers.Dense(32, activation='relu')(pool1)\n",
    "outputs = layers.Dense(1)(dense)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='Test')\n",
    "model.summary()\n",
    "    \n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")\n",
    "    \n",
    "history = model.fit(\n",
    "    X_train_dataset,\n",
    "    epochs=20,\n",
    "    validation_data=X_val_dataset\n",
    ")\n",
    "\n",
    "print(model.evaluate(X_test, y_test))\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8820b0-414b-4c03-a6dd-acbc476fe3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(None, 4))\n",
    "conv1 = layers.Conv1D(\n",
    "    filters=32,\n",
    "    kernel_size=10,\n",
    "    strides=1,\n",
    "    activation='relu',\n",
    "    padding='valid'\n",
    ")(inputs)\n",
    "# norm1 = layers.BatchNormalization()(conv1)\n",
    "pool1 = layers.MaxPooling1D(\n",
    "    pool_size=4,\n",
    "    strides=4\n",
    ")(conv1)\n",
    "bilstm = layers.Bidirectional(\n",
    "    layers.LSTM(units=64, return_sequences=True, recurrent_dropout=0.5),\n",
    "    merge_mode='mul'\n",
    ")(pool1)\n",
    "drop1 = layers.Dropout(\n",
    "    rate=0.45\n",
    ")(bilstm)\n",
    "# pool1 = layers.MaxPooling1D(\n",
    "#     pool_size=4,\n",
    "#     strides=4\n",
    "# )(drop1)\n",
    "pool1 = layers.GlobalMaxPool1D()(drop1)\n",
    "# flat = layers.Flatten()(drop1)\n",
    "dense = layers.Dense(32, activation='relu')(pool1)\n",
    "outputs = layers.Dense(1)(dense)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='Test')\n",
    "model.summary()\n",
    "    \n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")\n",
    "    \n",
    "history = model.fit(\n",
    "    X_train_dataset,\n",
    "    epochs=20,\n",
    "    validation_data=X_val_dataset\n",
    ")\n",
    "\n",
    "print(model.evaluate(X_test, y_test))\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de67ac-0026-42a6-b09b-f1fd60a0d74c",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0555c3-6e36-41eb-bb88-652a14aa79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zrimec_model():\n",
    "    inputs = layers.Input(shape=(None, 4))\n",
    "    # inputs = layers.Input(shape=(7999, 4))\n",
    "\n",
    "    conv1 = layers.Conv1D(\n",
    "        filters=32,\n",
    "        kernel_size=10,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    )(inputs)\n",
    "    norm1 = layers.BatchNormalization()(conv1)\n",
    "    drop1 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm1)\n",
    "    pool1 = layers.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(drop1)\n",
    "    conv2 = layers.Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=10,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    )(pool1)\n",
    "    norm2 = layers.BatchNormalization()(conv2)\n",
    "    drop2 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm2)\n",
    "    pool2 = layers.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(drop2)\n",
    "    conv3 = layers.Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=10,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    )(pool2)\n",
    "    norm3 = layers.BatchNormalization()(conv3)\n",
    "    drop3 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm3)\n",
    "    # pool3 = layers.MaxPooling1D(\n",
    "    #     pool_size=4,\n",
    "    #     strides=4\n",
    "    # )(drop3)\n",
    "    # flat = layers.Flatten()(pool3)\n",
    "    gmp = layers.GlobalMaxPool1D()(drop3)\n",
    "    dense = layers.Dense(\n",
    "        units=64,\n",
    "        activation='relu'\n",
    "    )(gmp)\n",
    "    norm4 = layers.BatchNormalization()(dense)\n",
    "    drop4 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm4)\n",
    "    outputs = layers.Dense(\n",
    "        units=1\n",
    "    )(drop4)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='ZrimecModel')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6ecde-954a-47a9-a7ad-ee9bfa13a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def danq_model():\n",
    "    inputs = layers.Input(shape=(None, 4))\n",
    "\n",
    "    conv = layers.Conv1D(\n",
    "        filters=320,\n",
    "        kernel_size=26,\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=13,\n",
    "        strides=13\n",
    "    )(conv)\n",
    "    drop1 = layers.Dropout(\n",
    "        rate=0.2\n",
    "    )(pool)\n",
    "\n",
    "    forward_layer = layers.LSTM(units=320, return_sequences=True)\n",
    "    backward_layer = layers.LSTM(units=320, return_sequences=True, go_backwards=True)\n",
    "    bilstm = layers.Bidirectional(\n",
    "        forward_layer, backward_layer=backward_layer\n",
    "    )(drop1)\n",
    "    drop2 = layers.Dropout(\n",
    "        rate=0.2\n",
    "    )(bilstm)\n",
    "    # flat = layers.Flatten()(drop2)\n",
    "    gmp = layers.GlobalMaxPool1D()(drop2)\n",
    "    dense1 = layers.Dense(\n",
    "        units=925,\n",
    "        activation='relu'\n",
    "    )(gmp)\n",
    "    outputs = layers.Dense(\n",
    "        units=1\n",
    "    )(dense1)\n",
    "    \n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='DanQModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbe2d2-38ec-49cb-8158-cd5a99b1a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def danq_refined_model():\n",
    "    inputs = layers.Input(shape=(None, 4))\n",
    "\n",
    "    conv = layers.Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(conv)\n",
    "    norm = layers.BatchNormalization()(pool)\n",
    "    # drop1 = layers.Dropout(\n",
    "    #     rate=0.2\n",
    "    # )(pool)\n",
    "\n",
    "    bilstm = layers.Bidirectional(\n",
    "        layers.LSTM(units=64, return_sequences=True, recurrent_dropout=0.25),\n",
    "        # merge_mode='mul'\n",
    "    )(norm)\n",
    "    drop2 = layers.Dropout(\n",
    "        rate=0.5\n",
    "    )(bilstm)\n",
    "    # flat = layers.Flatten()(drop2)\n",
    "    gmp = layers.GlobalMaxPool1D()(drop2)\n",
    "    dense1 = layers.Dense(\n",
    "        units=64,\n",
    "        activation='relu'\n",
    "    )(gmp)\n",
    "    outputs = layers.Dense(\n",
    "        units=1\n",
    "    )(dense1)\n",
    "    \n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='DanQRefModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c5168-f720-48b4-b777-01067098205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dan_zrimec_model():\n",
    "    # input\n",
    "    # setting fixed shape since the sequences are padded to the max length (threshold of preproc2)\n",
    "    inputs = layers.Input(shape=(None, 4))\n",
    "    # 1D convolution\n",
    "    conv = layers.Conv1D(\n",
    "        filters=320, \n",
    "        kernel_size=26, \n",
    "        strides=1, \n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    # batch normalization\n",
    "    norm = layers.BatchNormalization()(conv)\n",
    "    # maxpool\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=13,\n",
    "        strides=13\n",
    "    )(norm)\n",
    "    # dropout\n",
    "    drop = layers.Dropout(rate=0.1)(pool)\n",
    "    # bi-directional LSTM\n",
    "    bilstm = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            units=320, \n",
    "            dropout=0,\n",
    "            return_sequences=True,\n",
    "        ),\n",
    "        merge_mode='mul',\n",
    "        # input_shape=(8000, 4),\n",
    "    )(drop)\n",
    "    # maxpool\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=13,\n",
    "        strides=13,\n",
    "    )(bilstm)\n",
    "    drop = layers.Dropout(rate=0.1)(pool)\n",
    "    # flatten\n",
    "    # flat = layers.Flatten()(drop)\n",
    "    gmp = layers.GlobalMaxPool1D()(drop)\n",
    "    # fully connected\n",
    "    dense = layers.Dense(\n",
    "        units=64,\n",
    "        activation='relu',\n",
    "    )(gmp)\n",
    "    # batch normalization\n",
    "    norm = layers.BatchNormalization()(dense)\n",
    "    # dropout\n",
    "    drop = layers.Dropout(rate=0.1)(norm)\n",
    "    # dense\n",
    "    outputs = layers.Dense(units=1)(drop)\n",
    "\n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='BaselineModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468d333-3246-419a-95cd-4eb520fa40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augur_model():\n",
    "    inputs = layers.Input(shape=(None, 4))\n",
    "    conv = layers.Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    bilstm = layers.Bidirectional(layers.LSTM(units=64, recurrent_dropout=0.25))(conv)\n",
    "    drop1 = layers.Dropout(rate=0.2)(bilstm)\n",
    "    outputs = layers.Dense(units=1)(drop1)\n",
    "    \n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='AugurModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99d46776-4a76-4870-aa3f-565606a6ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(hist, start_epoch=1):\n",
    "    history_dict = hist.history\n",
    "    loss_values = history_dict[\"loss\"][start_epoch-1:]\n",
    "    val_loss_values = history_dict[\"val_loss\"][start_epoch-1:]\n",
    "    epochs = range(start_epoch, len(history_dict[\"loss\"]) + 1)\n",
    "    plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eed410-4510-4756-9c54-b72d2a88b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model, epochs=5, plot_epoch_start=1):\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        # optimizer=keras.optimizers.Adam(learning_rate=0.1, beta_1=0.999, beta_2=0.99, epsilon=1e-6),\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        # metrics=[keras.metrics.MeanAbsolutePercentageError(), keras.metrics.RootMeanSquaredError(), keras.metrics.MeanSquaredError(), keras.metrics.MeanAbsoluteError()],\n",
    "        metrics=keras.metrics.MeanAbsoluteError()\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        # X_train, \n",
    "        # y_train, \n",
    "        X_train_dataset,\n",
    "        # batch_size=64, \n",
    "        epochs=epochs,\n",
    "        # validation_data=(X_val, y_val), \n",
    "        validation_data=X_val_dataset\n",
    "        # callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Random prediction sample (truth, prediction):', y_test[0], y_pred[0])\n",
    "    \n",
    "    plot_loss(history, plot_epoch_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9caac-ddde-49e3-8cbf-678939080350",
   "metadata": {},
   "source": [
    "### Preliminary Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f55a9-a90d-4979-87b8-13399dd499b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(zrimec_model(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2632714-9505-4512-bebb-372f3d49366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(danq_model(), 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f55e6-bf26-4172-be44-1159ba096400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(danq_refined_model(), 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7873f96-828e-4299-a410-7fb2a3432ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(dan_zrimec_model(), 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfbadb-f47e-4c1e-b558-7ab8bfd1f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(augur_model(), 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b0a10-c0d7-4b3b-a20c-2a3a1937a807",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63783c6-429b-4b1d-a9fe-880a1bfe9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def danq_refined_model_hp_search(hp):\n",
    "    inputs = layers.Input(shape=(7999, 4))\n",
    "\n",
    "    conv = layers.Conv1D(\n",
    "        filters=hp.Int('conv_units', min_value=32, max_value=512, step=32),\n",
    "        kernel_size=hp.Int('kernel_size', min_value=3, max_value=36, step=3),\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=hp.Int('pool_size', min_value=2, max_value=20, step=2),\n",
    "        strides=None\n",
    "    )(conv)\n",
    "    norm = layers.BatchNormalization()(pool)\n",
    "    # drop1 = layers.Dropout(\n",
    "    #     rate=0.2\n",
    "    # )(pool)\n",
    "\n",
    "    bilstm = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            units=hp.Int('lstm_units', min_value=32, max_value=512, step=32), \n",
    "            return_sequences=True, \n",
    "            recurrent_dropout=hp.Float('recurrent_dropout', min_value=0.1, max_value=0.5, step=0.05)\n",
    "        ),\n",
    "        merge_mode=hp.Choice('merge_mode', ['concat', 'sum', 'mul'])\n",
    "    )(norm)\n",
    "    drop2 = layers.Dropout(\n",
    "        rate=hp.Float('rate', min_value=0.1, max_value=0.5, step=0.05)\n",
    "    )(bilstm)\n",
    "    flat = layers.Flatten()(drop2)\n",
    "    dense1 = layers.Dense(\n",
    "        units=hp.Int('dense_units', min_value=32, max_value=128, step=32),\n",
    "        activation='relu'\n",
    "    )(flat)\n",
    "    outputs = layers.Dense(\n",
    "        units=1\n",
    "    )(dense1)\n",
    "    \n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='DanQRefModel')\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        # optimizer=keras.optimizers.Adam(learning_rate=0.1, beta_1=0.999, beta_2=0.99, epsilon=1e-6),\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=[keras.metrics.MeanAbsolutePercentageError(), keras.metrics.MeanSquaredError(), keras.metrics.MeanAbsoluteError()],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f8e838-9aad-4c15-ae11-df1c37f6730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying that the model compiles\n",
    "danq_refined_model_hp_search(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d21df-f31d-40fc-ba0f-071bd51db6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the tuner\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    hypermodel=danq_refined_model_hp_search,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"hp_search\",\n",
    "    project_name=\"PTRaugur\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f73847-82bf-49c7-bf71-d39dcde324c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing an overview of the tunable parameters\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875a280-5676-488c-aad2-36fe9a61e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up an early stop callback function while tuning\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "]\n",
    "\n",
    "# running the tuning\n",
    "# tuner.search(\n",
    "#     X_train, y_train,\n",
    "#     batch_size=64, \n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9475e359-d923-486a-9867-82166ac93610",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bcfc1-1a04-4a74-9605-1d1f83757491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both zrimec and danq have a really bad performance (at least with 5 iterations, danq is slow because it's big)\n",
    "# model = zrimec_model()\n",
    "# model = danq_model()\n",
    "# model = baseline_model()\n",
    "# model = augur_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d846b8-9bdb-453e-b467-1f4f1a518c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b8982-e3d5-4544-9862-349265fce832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, 'baseline.png')\n",
    "# img = plt.imread('baseline.png')\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172dfc2-f846-4a93-8321-e38a56f857ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     loss=keras.losses.MeanSquaredError(),\n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=0.1, beta_1=0.999, beta_2=0.99, epsilon=1e-6),\n",
    "#     metrics=[keras.metrics.MeanAbsolutePercentageError(), keras.metrics.RootMeanSquaredError(), keras.losses.MeanSquaredError(), keras.metrics.MeanAbsoluteError()],\n",
    "# )\n",
    "\n",
    "# LOSS\n",
    "# works keras.losses.MeanSquaredError(),\n",
    "\n",
    "# METRIC\n",
    "# useless keras.metrics.Accuracy(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be5b09-0c52-4911-a579-c61318999317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"PTR_baseline.keras\", save_best_only=True)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c18cf-111f-4045-ab88-851efdab4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative methode to prepadding the sequences\n",
    "# X_train_ragged = tf.ragged.constant(X_train, dtype=tf.int8, ragged_rank=1, row_splits_dtype=tf.int32)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(tensor)\n",
    "# dataset = dataset.map(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7843173-f03d-4cdc-9e81-bf033163b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     X_train, \n",
    "#     y_train, \n",
    "#     batch_size=64, \n",
    "#     epochs=10, \n",
    "#     validation_data=(X_val, y_val), \n",
    "#     callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5389b58-c88c-491a-bd0b-b1ae96f74559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8bb01-bbe1-4c9e-b7a7-be82d3a61b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test[0], y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872ae84-78d2-4c18-b170-6561f595aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_dict = history.history\n",
    "# history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82c070-4f3c-47c9-8901-62c10e05b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b88240-e1e5-4f66-9de6-e549a3ae79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def full_model():\n",
    "#     # input\n",
    "#     inputs = keras.Input(shape=(None, 10))\n",
    "#     # 1D convolution\n",
    "#     conv = keras.Conv1D(\n",
    "#         filters=128, \n",
    "#         kernel_size=10, \n",
    "#         strides=1, \n",
    "#         activation='relu'\n",
    "#     )(inputs)\n",
    "#     # batch normalization\n",
    "#     norm = keras.BatchNormalization()(conv)\n",
    "#     # maxpool\n",
    "#     pool = keras.MaxPooling1D(\n",
    "#         pool_size=4,\n",
    "#         strides=4\n",
    "#     )(norm)\n",
    "#     # dropout\n",
    "#     drop = keras.Dropout(rate=0.2)(pool)\n",
    "#     # bi-directional LSTM\n",
    "#     bilstm = keras.Bidirectional(\n",
    "#         keras.LSTM(\n",
    "#             units=128,\n",
    "#             dropout=0\n",
    "#         ),\n",
    "#         merge_mode='concat'\n",
    "#     )(drop)\n",
    "#     # batch normalization\n",
    "#     norm = keras.BatchNormalization()(bilstm)\n",
    "#     # maxpool\n",
    "#     pool = keras.MaxPooling1D(\n",
    "#         pool_size=4,\n",
    "#         strides=4\n",
    "#     )(norm)\n",
    "#     # dropout\n",
    "#     drop = keras.Dropout(rate=0.2)(pool)\n",
    "#     # flatten\n",
    "#     flat = keras.Flatten()(drop)\n",
    "\n",
    "#     # second input\n",
    "#     inputs2 = keras.Input(shape=(29,))\n",
    "\n",
    "#     # concatenation\n",
    "#     conc = keras.Concatenate(axis=1)([inputs, inputs2])\n",
    "\n",
    "#     # fully connected\n",
    "#     dense = keras.Dense(\n",
    "#         units=64,\n",
    "#         activation='relu'\n",
    "#     )(conc)\n",
    "#     # batch normalization\n",
    "#     norm = keras.BatchNormalization()(dense)\n",
    "#     # dropout\n",
    "#     drop = keras.Dropout(rate=0.2)(norm)\n",
    "#     # dense\n",
    "#     outputs = keras.Dense(units=1)(drop)\n",
    "\n",
    "#     # model\n",
    "#     model = keras.Model(inputs=[inputs, inputs2], outputs=outputs, name='full_model')\n",
    "    \n",
    "#     return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
