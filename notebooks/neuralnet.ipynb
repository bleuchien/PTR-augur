{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e465583-fc98-4fda-937a-475748037b12",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "*fancy introduction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f12e085-6ce6-41e0-8f1e-1d35b23bf358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 21:48:11.976041: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-09 21:48:11.977352: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 21:48:11.995213: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-09 21:48:11.995229: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-09 21:48:11.995730: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-09 21:48:11.998770: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-09 21:48:11.999090: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 21:48:12.420658: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# library dependencies\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import lzma\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff0f512-caac-4cb6-b469-b2bbd23ad3f9",
   "metadata": {},
   "source": [
    "The following methods read the prepared data files from the pre processing step and return the lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9ecd0a7-8f25-4b5b-bfb0-b5375b32c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to store data as serialized binary structure lzma compressed\n",
    "def can_pickles(data, filename):\n",
    "    with lzma.LZMAFile(filename, 'wb') as f:\n",
    "        pickle.dump(data, f, pickle.DEFAULT_PROTOCOL)\n",
    "\n",
    "# method to retrieve data from a compressed pickle file (created with the method above)\n",
    "def uncan_pickles(filename):\n",
    "    with lzma.LZMAFile(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330afba-bf62-4e92-ad84-62921e42d31f",
   "metadata": {},
   "source": [
    "## Basic Neural Network\n",
    "\n",
    "*explain it in more detail*\n",
    "\n",
    "X holds a list of sequences one hot encoded\n",
    "\n",
    "y holds a list of PTR values as floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d1d16d-426c-460f-930d-0e91adba9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the prepared data back\n",
    "X = uncan_pickles('../data/onehot_x_lung.pickle.xz')\n",
    "y = uncan_pickles('../data/onehot_y_lung.pickle.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e91af-1782-4909-8191-87442cac791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad add sequence entries to the same length\n",
    "# done here for simplicity to find a good neural network\n",
    "# X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3603897-eca1-41be-a833-79e59f4b5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert type of target values from string to float\n",
    "y = np.array(y).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85086f0d-2d79-4ee8-900d-cad1873c1b64",
   "metadata": {},
   "source": [
    "Random sample from X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41525e09-813f-46b8-9f47-ebbd7381510c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85471826-2b3a-4371-8441-ae940ba8e580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694f3792-6d06-48e0-81af-f689cbb35c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8201"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of input sequences\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab69104-daa6-4989-89aa-2f6a71f34b0b",
   "metadata": {},
   "source": [
    "### Baseline PTR\n",
    "\n",
    "There is no common sense approach in finding a baseline for the protein-to-mRNA ratio of a particular mRNA sequence. This is what the *Basic Neural Network* approach is for - to determin a baseline and see if a slightly adapted neural network with feature engineered input can provide better predictions.\n",
    "\n",
    "But what can be done is to simply check the value range of the target PTRs, calculate mean and standard deviation. Given that the standard deviation is  small (12.5% of the value range) one can (stupidly) predict the mean value every time. From that it's possible to calculate the Mean Absolute Error (MAE) and compare that to the following neural network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bfa09b2-b288-4618-88a6-7799e1335da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.552 8.587 4.973957444214121 0.8835629329175175\n"
     ]
    }
   ],
   "source": [
    "# get some idea of the range of the PTR in the selected SAMPLE\n",
    "print(np.min(y), np.max(y), np.mean(y), np.std(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac9ba3da-9ab0-43f5-a923-63e94c580a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7055145713937325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple/dumb baseline mean absolute error of always predicting 4.974\n",
    "mae = np.mean(np.abs(np.array(y) - 4.974))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94586678-d302-4884-895d-d166c7e6f933",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "Split data in train and test subsets and then split the train subset again in train and validation.\n",
    "\n",
    "A simple verification if the X and y correlation are preserved on the split is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "271ef8f9-7f36-4c73-a448-5abbf294bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in train and test sub sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90b64b18-bbd8-4d4e-b6db-30d063c7eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train set again in train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39872e7f-c57d-4122-b0ea-3dbb7b24763d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the first unique PTR value that is also in y_train\n",
    "train_idx = 0\n",
    "for i in range(len(y)):\n",
    "    count = 0\n",
    "    for l in range(len(y)):\n",
    "        if i != l and y[i] == y[l]:\n",
    "            count += 1\n",
    "            continue\n",
    "    if count == 0:\n",
    "        for m in range(len(y_train)):\n",
    "            if y[i] == y_train[m]:\n",
    "                train_idx = m\n",
    "                break\n",
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ad195bb-8171-4ed0-a232-b561d0942a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       [1, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a sample\n",
    "X_train[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa42f36-5ebf-4541-9c2c-ecc7dece6446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.377"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the matching target\n",
    "search_y = y_train[train_idx]\n",
    "search_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7175df2-2e75-4fcd-8d66-6adf3f470b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8194\n"
     ]
    }
   ],
   "source": [
    "# find the target value in the raw dataset\n",
    "full_idx = 0\n",
    "for i in range(len(y)):\n",
    "    if y[i] == search_y:\n",
    "        print(i)\n",
    "        full_idx = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9857baf8-466f-4316-8335-e23a69b1c5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# compare if the raw dataset entry matches the subset entry\n",
    "if X[full_idx].all() == X_train[train_idx].all():\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37bd9c-8751-438c-a09a-633a050d5ee7",
   "metadata": {},
   "source": [
    "### Sort Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ce734dc-d388-4eaa-89e2-9ff29f0ff59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an inhomogenous numpy array from the training set\n",
    "X_train = np.array(X_train, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "202e05e3-0b6e-40ec-93f0-ab5bb51b3dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an array containing the sequence lengths\n",
    "sequence_lengths = list(map(lambda x: len(x), X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c1bf6e-6f11-4bb3-b6c7-a113e31f360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the array but only get the indices\n",
    "sorted_indices = np.argsort(sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72c9666d-018e-4338-a7cd-c6ac0e3fdabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1140,  657, 1659, ...,   71, 4128, 5096])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5236ee90-c6bd-4483-9328-09c28bfa3cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now sort the X and y train arrays according to the sorted indicds\n",
    "X_train = X_train[sorted_indices]\n",
    "y_train = y_train[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5ded927-98ca-40e1-b7e1-779ad6c5c25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# check if the previously found values still correlate\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i] == search_y:\n",
    "        print(X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e51d5a-aaf5-4507-be4c-9d44d06a457d",
   "metadata": {},
   "source": [
    "### Ragged Tensor Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f218654e-0434-4ae2-8472-93003397a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does not work since the sequences are of different length\n",
    "# X_test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "169ae758-42e2-4f8b-9d32-7d64f8322c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = tf.ragged.constant(X_train, dtype=tf.int8, ragged_rank=1, row_splits_dtype=tf.int32)\n",
    "X_val_tensor = tf.ragged.constant(X_val, dtype=tf.int8, ragged_rank=1, row_splits_dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8348ae2-0d05-4bf3-b64d-898eb5a9ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tensor, y_train))\n",
    "X_val_dataset = tf.data.Dataset.from_tensor_slices((X_val_tensor, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15d3004d-f438-48c2-b079-22fc282122e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RaggedTensorSpec(TensorShape([None, 4]), tf.int8, 0, tf.int32),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf34f643-79a9-469b-9353-7f60950f09f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RaggedTensorSpec(TensorShape([None, 4]), tf.int8, 0, tf.int32),\n",
       " TensorSpec(shape=(), dtype=tf.float64, name=None))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8502042d-58f5-4538-8578-e403365e1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded batches from ragged tensors are not supported (yet)\n",
    "# it needs a work around creating a uniform tensor\n",
    "# idea from : https://github.com/tensorflow/tensorflow/issues/39163\n",
    "def reformat(data, label):\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc3c4a63-47db-4263-a288-5969b7dbb6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_dataset = X_train_dataset.map(reformat)\n",
    "X_val_dataset = X_val_dataset.map(reformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c70893c0-2060-4ae7-9e2a-0cdbeb97921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataset (again) and create padded batches\n",
    "batch_size = 32\n",
    "X_train_dataset = X_train_dataset.shuffle(buffer_size=len(X_train), seed=1202).padded_batch(batch_size)\n",
    "X_val_dataset = X_val_dataset.shuffle(buffer_size=len(X_val), seed=1202).padded_batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be515ae3-b63a-4282-a614-d550e9d5369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optinally repeat the dataset multiple times -> WHY?\n",
    "# rep = 3\n",
    "# X_train_dataset = X_train_dataset.repeat(rep)\n",
    "# X_val_dataset = X_val_dataset.repeat(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00b046a1-22d0-42a9-94c0-7288e217425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalen = []\n",
    "ds_iterator = iter(X_train_dataset)\n",
    "for data, label in ds_iterator:\n",
    "    datalen.append(len(data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fbf6d94-f7c8-4613-8834-036bdd4d0190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7958, 7615, 6848, 7088, 7937]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalen[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14065709-7726-4aea-9188-83f593189fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 8ms/step - loss: 20.0194 - mae: 4.3844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb5c7e023d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing if keras can use the dataset\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='relu', input_shape=(None,4)),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit(X_train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fe7debc6-1868-4b2a-8d44-f414532051bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Test\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, None, 4)]         0         \n",
      "                                                                 \n",
      " conv1d_24 (Conv1D)          (None, None, 32)          1312      \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, None, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, None, 32)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Gl  (None, 32)                0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1985 (7.75 KB)\n",
      "Trainable params: 1921 (7.50 KB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n",
      "164/164 [==============================] - 5s 27ms/step - loss: 2.2875 - mean_absolute_error: 1.1051 - val_loss: 19.0174 - val_mean_absolute_error: 4.2728\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(None, 4))\n",
    "conv1 = layers.Conv1D(\n",
    "    filters=32,\n",
    "    kernel_size=10,\n",
    "    strides=1,\n",
    "    activation='relu',\n",
    "    padding='valid'\n",
    ")(inputs)\n",
    "norm1 = layers.BatchNormalization()(conv1)\n",
    "drop1 = layers.Dropout(\n",
    "    rate=0.1\n",
    ")(norm1)\n",
    "# pool1 = layers.MaxPooling1D(\n",
    "#     pool_size=4,\n",
    "#     strides=4\n",
    "# )(drop1)\n",
    "pool1 = layers.GlobalMaxPool1D()(drop1)\n",
    "# flat = layers.Flatten()(drop1)\n",
    "dense = layers.Dense(16, activation='relu')(pool1)\n",
    "outputs = layers.Dense(1)(dense)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='Test')\n",
    "model.summary()\n",
    "    \n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.MeanAbsoluteError()],\n",
    ")\n",
    "    \n",
    "history = model.fit(\n",
    "    X_train_dataset,\n",
    "    epochs=1,\n",
    "    validation_data=X_val_dataset\n",
    ")\n",
    "    \n",
    "# y_pred = model.predict(X_test)\n",
    "# print('Random prediction sample (truth, prediction):', y_test[0], y_pred[0])\n",
    "\n",
    "# plot_loss(history, plot_epoch_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de67ac-0026-42a6-b09b-f1fd60a0d74c",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d0555c3-6e36-41eb-bb88-652a14aa79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zrimec_model():\n",
    "    inputs = layers.Input(shape=(None, 4))\n",
    "    # inputs = layers.Input(shape=(7999, 4))\n",
    "\n",
    "    conv1 = layers.Conv1D(\n",
    "        filters=32,\n",
    "        kernel_size=10,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    )(inputs)\n",
    "    norm1 = layers.BatchNormalization()(conv1)\n",
    "    drop1 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm1)\n",
    "    pool1 = layers.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(drop1)\n",
    "    conv2 = layers.Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=10,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    )(pool1)\n",
    "    norm2 = layers.BatchNormalization()(conv2)\n",
    "    drop2 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm2)\n",
    "    pool2 = layers.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(drop2)\n",
    "    conv3 = layers.Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=10,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    )(pool2)\n",
    "    norm3 = layers.BatchNormalization()(conv3)\n",
    "    drop3 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm3)\n",
    "    # pool3 = layers.MaxPooling1D(\n",
    "    #     pool_size=4,\n",
    "    #     strides=4\n",
    "    # )(drop3)\n",
    "    # flat = layers.Flatten()(pool3)\n",
    "    gmp = layers.GlobalMaxPool1D()(drop3)\n",
    "    dense = layers.Dense(\n",
    "        units=64,\n",
    "        activation='relu'\n",
    "    )(gmp)\n",
    "    norm4 = layers.BatchNormalization()(dense)\n",
    "    drop4 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm4)\n",
    "    outputs = layers.Dense(\n",
    "        units=1\n",
    "    )(drop4)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='ZrimecModel')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cb6ecde-954a-47a9-a7ad-ee9bfa13a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def danq_model():\n",
    "    inputs = layers.Input(shape=(7999, 4))\n",
    "\n",
    "    conv = layers.Conv1D(\n",
    "        filters=320,\n",
    "        kernel_size=26,\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=13,\n",
    "        strides=13\n",
    "    )(conv)\n",
    "    drop1 = layers.Dropout(\n",
    "        rate=0.2\n",
    "    )(pool)\n",
    "\n",
    "    forward_layer = layers.LSTM(units=320, return_sequences=True)\n",
    "    backward_layer = layers.LSTM(units=320, return_sequences=True, go_backwards=True)\n",
    "    bilstm = layers.Bidirectional(\n",
    "        forward_layer, backward_layer=backward_layer\n",
    "    )(drop1)\n",
    "    drop2 = layers.Dropout(\n",
    "        rate=0.2\n",
    "    )(bilstm)\n",
    "    # flat = layers.Flatten()(drop2)\n",
    "    gmp = layers.GlobalMaxPool1D()(drop2)\n",
    "    dense1 = layers.Dense(\n",
    "        units=925,\n",
    "        activation='relu'\n",
    "    )(gmp)\n",
    "    outputs = layers.Dense(\n",
    "        units=1\n",
    "    )(dense1)\n",
    "    \n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='DanQModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1cbe2d2-38ec-49cb-8158-cd5a99b1a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def danq_refined_model():\n",
    "    inputs = layers.Input(shape=(7999, 4))\n",
    "\n",
    "    conv = layers.Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(conv)\n",
    "    norm = layers.BatchNormalization()(pool)\n",
    "    # drop1 = layers.Dropout(\n",
    "    #     rate=0.2\n",
    "    # )(pool)\n",
    "\n",
    "    bilstm = layers.Bidirectional(\n",
    "        layers.LSTM(units=64, return_sequences=True, recurrent_dropout=0.25),\n",
    "        # merge_mode='mul'\n",
    "    )(norm)\n",
    "    drop2 = layers.Dropout(\n",
    "        rate=0.5\n",
    "    )(bilstm)\n",
    "    # flat = layers.Flatten()(drop2)\n",
    "    gmp = layers.GlobalMaxPool1D()(drop2)\n",
    "    dense1 = layers.Dense(\n",
    "        units=64,\n",
    "        activation='relu'\n",
    "    )(gmp)\n",
    "    outputs = layers.Dense(\n",
    "        units=1\n",
    "    )(dense1)\n",
    "    \n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='DanQRefModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1a4c5168-f720-48b4-b777-01067098205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dan_zrimec_model():\n",
    "    # input\n",
    "    # setting fixed shape since the sequences are padded to the max length (threshold of preproc2)\n",
    "    inputs = layers.Input(shape=(7999, 4))\n",
    "    # 1D convolution\n",
    "    conv = layers.Conv1D(\n",
    "        filters=320, \n",
    "        kernel_size=26, \n",
    "        strides=1, \n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    # batch normalization\n",
    "    norm = layers.BatchNormalization()(conv)\n",
    "    # maxpool\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=13,\n",
    "        strides=13\n",
    "    )(norm)\n",
    "    # dropout\n",
    "    drop = layers.Dropout(rate=0.1)(pool)\n",
    "    # bi-directional LSTM\n",
    "    bilstm = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            units=320, \n",
    "            dropout=0,\n",
    "            return_sequences=True,\n",
    "        ),\n",
    "        merge_mode='mul',\n",
    "        # input_shape=(8000, 4),\n",
    "    )(drop)\n",
    "    # maxpool\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=13,\n",
    "        strides=13,\n",
    "    )(bilstm)\n",
    "    drop = layers.Dropout(rate=0.1)(pool)\n",
    "    # flatten\n",
    "    # flat = layers.Flatten()(drop)\n",
    "    gmp = layers.GlobalMaxPool1D()(drop)\n",
    "    # fully connected\n",
    "    dense = layers.Dense(\n",
    "        units=64,\n",
    "        activation='relu',\n",
    "    )(gmp)\n",
    "    # batch normalization\n",
    "    norm = layers.BatchNormalization()(dense)\n",
    "    # dropout\n",
    "    drop = layers.Dropout(rate=0.1)(norm)\n",
    "    # dense\n",
    "    outputs = layers.Dense(units=1)(drop)\n",
    "\n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='BaselineModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d468d333-3246-419a-95cd-4eb520fa40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augur_model():\n",
    "    inputs = layers.Input(shape=(7999, 4))\n",
    "    conv = layers.Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=3,\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    bilstm = layers.Bidirectional(layers.LSTM(units=64, recurrent_dropout=0.25))(conv)\n",
    "    drop1 = layers.Dropout(rate=0.2)(bilstm)\n",
    "    outputs = layers.Dense(units=1)(drop1)\n",
    "    \n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='AugurModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99d46776-4a76-4870-aa3f-565606a6ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(hist, start_epoch=1):\n",
    "    history_dict = hist.history\n",
    "    loss_values = history_dict[\"loss\"][start_epoch-1:]\n",
    "    val_loss_values = history_dict[\"val_loss\"][start_epoch-1:]\n",
    "    epochs = range(start_epoch, len(history_dict[\"loss\"]) + 1)\n",
    "    plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06eed410-4510-4756-9c54-b72d2a88b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model, epochs=5, plot_epoch_start=1):\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        # optimizer=keras.optimizers.Adam(learning_rate=0.1, beta_1=0.999, beta_2=0.99, epsilon=1e-6),\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=[keras.metrics.MeanAbsolutePercentageError(), keras.metrics.RootMeanSquaredError(), keras.metrics.MeanSquaredError(), keras.metrics.MeanAbsoluteError()],\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        # X_train, \n",
    "        # y_train, \n",
    "        X_train_dataset,\n",
    "        # batch_size=64, \n",
    "        epochs=epochs,\n",
    "        # validation_data=(X_val, y_val), \n",
    "        validation_data=X_val_dataset\n",
    "        # callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Random prediction sample (truth, prediction):', y_test[0], y_pred[0])\n",
    "    \n",
    "    plot_loss(history, plot_epoch_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9caac-ddde-49e3-8cbf-678939080350",
   "metadata": {},
   "source": [
    "### Preliminary Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f55a9-a90d-4979-87b8-13399dd499b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ZrimecModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, None, 4)]         0         \n",
      "                                                                 \n",
      " conv1d_31 (Conv1D)          (None, None, 32)          1312      \n",
      "                                                                 \n",
      " batch_normalization_35 (Ba  (None, None, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, None, 32)          0         \n",
      "                                                                 \n",
      " max_pooling1d_22 (MaxPooli  (None, None, 32)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_32 (Conv1D)          (None, None, 64)          20544     \n",
      "                                                                 \n",
      " batch_normalization_36 (Ba  (None, None, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, None, 64)          0         \n",
      "                                                                 \n",
      " max_pooling1d_23 (MaxPooli  (None, None, 64)          0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_33 (Conv1D)          (None, None, 128)         82048     \n",
      "                                                                 \n",
      " batch_normalization_37 (Ba  (None, None, 128)         512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " global_max_pooling1d_5 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_38 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113377 (442.88 KB)\n",
      "Trainable params: 112801 (440.63 KB)\n",
      "Non-trainable params: 576 (2.25 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "164/164 [==============================] - 15s 84ms/step - loss: 16.5554 - mean_absolute_percentage_error: 76.1744 - root_mean_squared_error: 4.0688 - mean_squared_error: 16.5554 - mean_absolute_error: 3.8274 - val_loss: 2.1046 - val_mean_absolute_percentage_error: 28.2987 - val_root_mean_squared_error: 1.4507 - val_mean_squared_error: 2.1046 - val_mean_absolute_error: 1.2020\n",
      "Epoch 2/100\n",
      "164/164 [==============================] - 14s 84ms/step - loss: 2.1445 - mean_absolute_percentage_error: 23.5971 - root_mean_squared_error: 1.4644 - mean_squared_error: 2.1445 - mean_absolute_error: 1.1657 - val_loss: 73.9370 - val_mean_absolute_percentage_error: 181.8967 - val_root_mean_squared_error: 8.5987 - val_mean_squared_error: 73.9370 - val_mean_absolute_error: 8.5409\n",
      "Epoch 3/100\n",
      "164/164 [==============================] - 13s 81ms/step - loss: 1.1197 - mean_absolute_percentage_error: 17.7181 - root_mean_squared_error: 1.0581 - mean_squared_error: 1.1197 - mean_absolute_error: 0.8060 - val_loss: 16.1604 - val_mean_absolute_percentage_error: 39.6924 - val_root_mean_squared_error: 4.0200 - val_mean_squared_error: 16.1604 - val_mean_absolute_error: 1.9822\n",
      "Epoch 4/100\n",
      "164/164 [==============================] - 13s 81ms/step - loss: 1.1313 - mean_absolute_percentage_error: 17.9461 - root_mean_squared_error: 1.0636 - mean_squared_error: 1.1313 - mean_absolute_error: 0.8173 - val_loss: 11.5484 - val_mean_absolute_percentage_error: 28.4186 - val_root_mean_squared_error: 3.3983 - val_mean_squared_error: 11.5484 - val_mean_absolute_error: 1.3954\n",
      "Epoch 5/100\n",
      "164/164 [==============================] - 13s 77ms/step - loss: 1.0527 - mean_absolute_percentage_error: 17.3199 - root_mean_squared_error: 1.0260 - mean_squared_error: 1.0527 - mean_absolute_error: 0.7851 - val_loss: 7.5510 - val_mean_absolute_percentage_error: 30.3187 - val_root_mean_squared_error: 2.7479 - val_mean_squared_error: 7.5510 - val_mean_absolute_error: 1.3169\n",
      "Epoch 6/100\n",
      "164/164 [==============================] - 13s 78ms/step - loss: 0.9871 - mean_absolute_percentage_error: 16.8553 - root_mean_squared_error: 0.9935 - mean_squared_error: 0.9871 - mean_absolute_error: 0.7644 - val_loss: 3.1432 - val_mean_absolute_percentage_error: 20.8267 - val_root_mean_squared_error: 1.7729 - val_mean_squared_error: 3.1432 - val_mean_absolute_error: 0.9983\n",
      "Epoch 7/100\n",
      "164/164 [==============================] - 12s 73ms/step - loss: 1.0766 - mean_absolute_percentage_error: 17.1017 - root_mean_squared_error: 1.0376 - mean_squared_error: 1.0766 - mean_absolute_error: 0.7744 - val_loss: 3.6663 - val_mean_absolute_percentage_error: 21.3413 - val_root_mean_squared_error: 1.9147 - val_mean_squared_error: 3.6663 - val_mean_absolute_error: 0.9746\n",
      "Epoch 8/100\n",
      "164/164 [==============================] - 12s 74ms/step - loss: 0.9396 - mean_absolute_percentage_error: 16.6346 - root_mean_squared_error: 0.9693 - mean_squared_error: 0.9396 - mean_absolute_error: 0.7513 - val_loss: 4.0521 - val_mean_absolute_percentage_error: 28.0489 - val_root_mean_squared_error: 2.0130 - val_mean_squared_error: 4.0521 - val_mean_absolute_error: 1.2078\n",
      "Epoch 9/100\n",
      "164/164 [==============================] - 12s 71ms/step - loss: 0.9666 - mean_absolute_percentage_error: 16.6692 - root_mean_squared_error: 0.9832 - mean_squared_error: 0.9666 - mean_absolute_error: 0.7579 - val_loss: 1.6681 - val_mean_absolute_percentage_error: 18.0896 - val_root_mean_squared_error: 1.2916 - val_mean_squared_error: 1.6681 - val_mean_absolute_error: 0.8369\n",
      "Epoch 10/100\n",
      "164/164 [==============================] - 11s 68ms/step - loss: 0.8934 - mean_absolute_percentage_error: 16.2417 - root_mean_squared_error: 0.9452 - mean_squared_error: 0.8934 - mean_absolute_error: 0.7343 - val_loss: 2.6099 - val_mean_absolute_percentage_error: 19.7397 - val_root_mean_squared_error: 1.6155 - val_mean_squared_error: 2.6099 - val_mean_absolute_error: 0.9028\n",
      "Epoch 11/100\n",
      "164/164 [==============================] - 11s 70ms/step - loss: 0.8861 - mean_absolute_percentage_error: 16.1442 - root_mean_squared_error: 0.9413 - mean_squared_error: 0.8861 - mean_absolute_error: 0.7300 - val_loss: 1.2270 - val_mean_absolute_percentage_error: 17.7502 - val_root_mean_squared_error: 1.1077 - val_mean_squared_error: 1.2270 - val_mean_absolute_error: 0.7605\n",
      "Epoch 12/100\n",
      "164/164 [==============================] - 12s 72ms/step - loss: 0.8867 - mean_absolute_percentage_error: 16.0788 - root_mean_squared_error: 0.9417 - mean_squared_error: 0.8867 - mean_absolute_error: 0.7277 - val_loss: 3.0697 - val_mean_absolute_percentage_error: 21.4088 - val_root_mean_squared_error: 1.7521 - val_mean_squared_error: 3.0697 - val_mean_absolute_error: 0.9436\n",
      "Epoch 13/100\n",
      "164/164 [==============================] - 12s 72ms/step - loss: 0.8660 - mean_absolute_percentage_error: 15.8140 - root_mean_squared_error: 0.9306 - mean_squared_error: 0.8660 - mean_absolute_error: 0.7177 - val_loss: 1.2186 - val_mean_absolute_percentage_error: 17.4683 - val_root_mean_squared_error: 1.1039 - val_mean_squared_error: 1.2186 - val_mean_absolute_error: 0.7759\n",
      "Epoch 14/100\n",
      "164/164 [==============================] - 12s 72ms/step - loss: 0.8338 - mean_absolute_percentage_error: 15.7289 - root_mean_squared_error: 0.9131 - mean_squared_error: 0.8338 - mean_absolute_error: 0.7144 - val_loss: 1.1302 - val_mean_absolute_percentage_error: 16.7326 - val_root_mean_squared_error: 1.0631 - val_mean_squared_error: 1.1302 - val_mean_absolute_error: 0.7425\n",
      "Epoch 15/100\n",
      "164/164 [==============================] - 12s 72ms/step - loss: 0.8151 - mean_absolute_percentage_error: 15.4265 - root_mean_squared_error: 0.9028 - mean_squared_error: 0.8151 - mean_absolute_error: 0.6990 - val_loss: 2.2043 - val_mean_absolute_percentage_error: 18.9280 - val_root_mean_squared_error: 1.4847 - val_mean_squared_error: 2.2043 - val_mean_absolute_error: 0.8763\n",
      "Epoch 16/100\n",
      "164/164 [==============================] - 12s 74ms/step - loss: 0.8007 - mean_absolute_percentage_error: 15.3143 - root_mean_squared_error: 0.8948 - mean_squared_error: 0.8007 - mean_absolute_error: 0.6948 - val_loss: 1.2273 - val_mean_absolute_percentage_error: 17.0985 - val_root_mean_squared_error: 1.1078 - val_mean_squared_error: 1.2273 - val_mean_absolute_error: 0.7746\n",
      "Epoch 17/100\n",
      "164/164 [==============================] - 12s 72ms/step - loss: 0.7816 - mean_absolute_percentage_error: 15.2721 - root_mean_squared_error: 0.8841 - mean_squared_error: 0.7816 - mean_absolute_error: 0.6929 - val_loss: 7.8635 - val_mean_absolute_percentage_error: 24.9304 - val_root_mean_squared_error: 2.8042 - val_mean_squared_error: 7.8635 - val_mean_absolute_error: 1.0847\n",
      "Epoch 18/100\n",
      "164/164 [==============================] - 11s 69ms/step - loss: 0.9327 - mean_absolute_percentage_error: 16.5277 - root_mean_squared_error: 0.9658 - mean_squared_error: 0.9327 - mean_absolute_error: 0.7536 - val_loss: 2.8141 - val_mean_absolute_percentage_error: 24.0567 - val_root_mean_squared_error: 1.6775 - val_mean_squared_error: 2.8141 - val_mean_absolute_error: 1.2447\n",
      "Epoch 19/100\n",
      "164/164 [==============================] - 12s 73ms/step - loss: 0.9418 - mean_absolute_percentage_error: 16.9473 - root_mean_squared_error: 0.9705 - mean_squared_error: 0.9418 - mean_absolute_error: 0.7669 - val_loss: 1.1982 - val_mean_absolute_percentage_error: 17.7312 - val_root_mean_squared_error: 1.0946 - val_mean_squared_error: 1.1982 - val_mean_absolute_error: 0.8093\n",
      "Epoch 20/100\n",
      "164/164 [==============================] - 12s 72ms/step - loss: 0.8711 - mean_absolute_percentage_error: 16.4357 - root_mean_squared_error: 0.9333 - mean_squared_error: 0.8711 - mean_absolute_error: 0.7412 - val_loss: 1.1987 - val_mean_absolute_percentage_error: 17.5489 - val_root_mean_squared_error: 1.0949 - val_mean_squared_error: 1.1987 - val_mean_absolute_error: 0.7889\n",
      "Epoch 21/100\n",
      "164/164 [==============================] - 12s 74ms/step - loss: 0.8577 - mean_absolute_percentage_error: 16.1965 - root_mean_squared_error: 0.9261 - mean_squared_error: 0.8577 - mean_absolute_error: 0.7316 - val_loss: 2.7054 - val_mean_absolute_percentage_error: 24.2009 - val_root_mean_squared_error: 1.6448 - val_mean_squared_error: 2.7054 - val_mean_absolute_error: 1.0256\n",
      "Epoch 22/100\n",
      "164/164 [==============================] - 12s 74ms/step - loss: 0.8290 - mean_absolute_percentage_error: 15.9664 - root_mean_squared_error: 0.9105 - mean_squared_error: 0.8290 - mean_absolute_error: 0.7226 - val_loss: 5.8796 - val_mean_absolute_percentage_error: 23.9989 - val_root_mean_squared_error: 2.4248 - val_mean_squared_error: 5.8796 - val_mean_absolute_error: 1.1222\n",
      "Epoch 23/100\n",
      "164/164 [==============================] - 12s 70ms/step - loss: 0.8147 - mean_absolute_percentage_error: 15.9016 - root_mean_squared_error: 0.9026 - mean_squared_error: 0.8147 - mean_absolute_error: 0.7189 - val_loss: 2.5761 - val_mean_absolute_percentage_error: 19.9153 - val_root_mean_squared_error: 1.6050 - val_mean_squared_error: 2.5761 - val_mean_absolute_error: 0.8709\n",
      "Epoch 24/100\n",
      "164/164 [==============================] - 11s 68ms/step - loss: 0.7784 - mean_absolute_percentage_error: 15.4619 - root_mean_squared_error: 0.8823 - mean_squared_error: 0.7784 - mean_absolute_error: 0.6997 - val_loss: 4.1864 - val_mean_absolute_percentage_error: 21.7748 - val_root_mean_squared_error: 2.0461 - val_mean_squared_error: 4.1864 - val_mean_absolute_error: 1.0121\n",
      "Epoch 25/100\n",
      "164/164 [==============================] - 12s 72ms/step - loss: 0.7746 - mean_absolute_percentage_error: 15.3045 - root_mean_squared_error: 0.8801 - mean_squared_error: 0.7746 - mean_absolute_error: 0.6932 - val_loss: 6.9366 - val_mean_absolute_percentage_error: 24.5118 - val_root_mean_squared_error: 2.6337 - val_mean_squared_error: 6.9366 - val_mean_absolute_error: 1.0991\n",
      "Epoch 26/100\n",
      "164/164 [==============================] - 12s 71ms/step - loss: 0.7412 - mean_absolute_percentage_error: 15.0574 - root_mean_squared_error: 0.8609 - mean_squared_error: 0.7412 - mean_absolute_error: 0.6819 - val_loss: 0.9075 - val_mean_absolute_percentage_error: 16.1480 - val_root_mean_squared_error: 0.9526 - val_mean_squared_error: 0.9075 - val_mean_absolute_error: 0.7839\n",
      "Epoch 27/100\n",
      "164/164 [==============================] - 12s 70ms/step - loss: 0.7057 - mean_absolute_percentage_error: 14.7024 - root_mean_squared_error: 0.8400 - mean_squared_error: 0.7057 - mean_absolute_error: 0.6661 - val_loss: 0.7852 - val_mean_absolute_percentage_error: 15.8145 - val_root_mean_squared_error: 0.8861 - val_mean_squared_error: 0.7852 - val_mean_absolute_error: 0.6891\n",
      "Epoch 28/100\n",
      "164/164 [==============================] - 11s 70ms/step - loss: 0.6828 - mean_absolute_percentage_error: 14.3513 - root_mean_squared_error: 0.8263 - mean_squared_error: 0.6828 - mean_absolute_error: 0.6533 - val_loss: 1.0104 - val_mean_absolute_percentage_error: 16.4420 - val_root_mean_squared_error: 1.0052 - val_mean_squared_error: 1.0104 - val_mean_absolute_error: 0.7071\n",
      "Epoch 29/100\n",
      "164/164 [==============================] - 12s 70ms/step - loss: 0.6467 - mean_absolute_percentage_error: 13.9852 - root_mean_squared_error: 0.8042 - mean_squared_error: 0.6467 - mean_absolute_error: 0.6357 - val_loss: 1.4334 - val_mean_absolute_percentage_error: 22.6444 - val_root_mean_squared_error: 1.1972 - val_mean_squared_error: 1.4334 - val_mean_absolute_error: 0.9464\n",
      "Epoch 30/100\n",
      "164/164 [==============================] - 11s 70ms/step - loss: 0.6407 - mean_absolute_percentage_error: 13.9119 - root_mean_squared_error: 0.8004 - mean_squared_error: 0.6407 - mean_absolute_error: 0.6333 - val_loss: 1.4820 - val_mean_absolute_percentage_error: 23.0156 - val_root_mean_squared_error: 1.2174 - val_mean_squared_error: 1.4820 - val_mean_absolute_error: 0.9622\n",
      "Epoch 31/100\n",
      "164/164 [==============================] - 12s 71ms/step - loss: 0.6062 - mean_absolute_percentage_error: 13.4978 - root_mean_squared_error: 0.7786 - mean_squared_error: 0.6062 - mean_absolute_error: 0.6175 - val_loss: 1.4557 - val_mean_absolute_percentage_error: 22.8476 - val_root_mean_squared_error: 1.2065 - val_mean_squared_error: 1.4557 - val_mean_absolute_error: 0.9567\n",
      "Epoch 32/100\n",
      "164/164 [==============================] - 12s 71ms/step - loss: 0.6002 - mean_absolute_percentage_error: 13.4673 - root_mean_squared_error: 0.7747 - mean_squared_error: 0.6002 - mean_absolute_error: 0.6165 - val_loss: 0.7721 - val_mean_absolute_percentage_error: 15.5328 - val_root_mean_squared_error: 0.8787 - val_mean_squared_error: 0.7721 - val_mean_absolute_error: 0.6970\n",
      "Epoch 33/100\n",
      "164/164 [==============================] - 11s 68ms/step - loss: 0.5696 - mean_absolute_percentage_error: 13.0553 - root_mean_squared_error: 0.7547 - mean_squared_error: 0.5696 - mean_absolute_error: 0.5995 - val_loss: 0.8966 - val_mean_absolute_percentage_error: 16.5698 - val_root_mean_squared_error: 0.9469 - val_mean_squared_error: 0.8966 - val_mean_absolute_error: 0.7176\n",
      "Epoch 34/100\n",
      "164/164 [==============================] - 12s 73ms/step - loss: 0.5487 - mean_absolute_percentage_error: 12.7597 - root_mean_squared_error: 0.7408 - mean_squared_error: 0.5487 - mean_absolute_error: 0.5851 - val_loss: 0.9610 - val_mean_absolute_percentage_error: 17.7336 - val_root_mean_squared_error: 0.9803 - val_mean_squared_error: 0.9610 - val_mean_absolute_error: 0.7566\n",
      "Epoch 35/100\n",
      "164/164 [==============================] - 12s 71ms/step - loss: 0.5241 - mean_absolute_percentage_error: 12.5580 - root_mean_squared_error: 0.7239 - mean_squared_error: 0.5241 - mean_absolute_error: 0.5789 - val_loss: 1.5010 - val_mean_absolute_percentage_error: 21.4066 - val_root_mean_squared_error: 1.2252 - val_mean_squared_error: 1.5010 - val_mean_absolute_error: 0.9034\n",
      "Epoch 36/100\n",
      "164/164 [==============================] - 12s 71ms/step - loss: 0.5024 - mean_absolute_percentage_error: 12.2731 - root_mean_squared_error: 0.7088 - mean_squared_error: 0.5024 - mean_absolute_error: 0.5650 - val_loss: 1.0500 - val_mean_absolute_percentage_error: 17.0639 - val_root_mean_squared_error: 1.0247 - val_mean_squared_error: 1.0500 - val_mean_absolute_error: 0.8413\n",
      "Epoch 37/100\n",
      "164/164 [==============================] - 12s 72ms/step - loss: 0.4852 - mean_absolute_percentage_error: 12.0228 - root_mean_squared_error: 0.6966 - mean_squared_error: 0.4852 - mean_absolute_error: 0.5560 - val_loss: 0.8413 - val_mean_absolute_percentage_error: 15.7662 - val_root_mean_squared_error: 0.9172 - val_mean_squared_error: 0.8413 - val_mean_absolute_error: 0.7459\n",
      "Epoch 38/100\n",
      "164/164 [==============================] - 12s 71ms/step - loss: 0.4726 - mean_absolute_percentage_error: 11.7632 - root_mean_squared_error: 0.6875 - mean_squared_error: 0.4726 - mean_absolute_error: 0.5460 - val_loss: 0.7799 - val_mean_absolute_percentage_error: 15.6177 - val_root_mean_squared_error: 0.8831 - val_mean_squared_error: 0.7799 - val_mean_absolute_error: 0.7029\n",
      "Epoch 39/100\n",
      "164/164 [==============================] - 11s 69ms/step - loss: 0.4477 - mean_absolute_percentage_error: 11.4609 - root_mean_squared_error: 0.6691 - mean_squared_error: 0.4477 - mean_absolute_error: 0.5315 - val_loss: 1.8287 - val_mean_absolute_percentage_error: 25.7560 - val_root_mean_squared_error: 1.3523 - val_mean_squared_error: 1.8287 - val_mean_absolute_error: 1.0852\n",
      "Epoch 40/100\n",
      "164/164 [==============================] - 12s 72ms/step - loss: 0.4375 - mean_absolute_percentage_error: 11.3815 - root_mean_squared_error: 0.6614 - mean_squared_error: 0.4375 - mean_absolute_error: 0.5307 - val_loss: 0.8078 - val_mean_absolute_percentage_error: 15.7865 - val_root_mean_squared_error: 0.8988 - val_mean_squared_error: 0.8078 - val_mean_absolute_error: 0.7248\n",
      "Epoch 41/100\n",
      "164/164 [==============================] - 11s 70ms/step - loss: 0.4276 - mean_absolute_percentage_error: 11.2158 - root_mean_squared_error: 0.6539 - mean_squared_error: 0.4276 - mean_absolute_error: 0.5221 - val_loss: 1.1547 - val_mean_absolute_percentage_error: 19.8185 - val_root_mean_squared_error: 1.0746 - val_mean_squared_error: 1.1547 - val_mean_absolute_error: 0.8369\n",
      "Epoch 42/100\n",
      "164/164 [==============================] - 12s 74ms/step - loss: 0.3920 - mean_absolute_percentage_error: 10.6744 - root_mean_squared_error: 0.6261 - mean_squared_error: 0.3920 - mean_absolute_error: 0.4956 - val_loss: 0.8309 - val_mean_absolute_percentage_error: 15.8669 - val_root_mean_squared_error: 0.9115 - val_mean_squared_error: 0.8309 - val_mean_absolute_error: 0.7322\n",
      "Epoch 43/100\n",
      "164/164 [==============================] - 12s 71ms/step - loss: 0.3902 - mean_absolute_percentage_error: 10.7011 - root_mean_squared_error: 0.6246 - mean_squared_error: 0.3902 - mean_absolute_error: 0.4992 - val_loss: 1.3597 - val_mean_absolute_percentage_error: 21.6587 - val_root_mean_squared_error: 1.1661 - val_mean_squared_error: 1.3597 - val_mean_absolute_error: 0.9106\n",
      "Epoch 44/100\n",
      "164/164 [==============================] - 12s 74ms/step - loss: 0.3854 - mean_absolute_percentage_error: 10.5968 - root_mean_squared_error: 0.6208 - mean_squared_error: 0.3854 - mean_absolute_error: 0.4948 - val_loss: 0.9734 - val_mean_absolute_percentage_error: 17.9226 - val_root_mean_squared_error: 0.9866 - val_mean_squared_error: 0.9734 - val_mean_absolute_error: 0.7646\n",
      "Epoch 45/100\n",
      "164/164 [==============================] - 12s 73ms/step - loss: 0.3542 - mean_absolute_percentage_error: 10.1132 - root_mean_squared_error: 0.5951 - mean_squared_error: 0.3542 - mean_absolute_error: 0.4738 - val_loss: 1.2009 - val_mean_absolute_percentage_error: 20.1926 - val_root_mean_squared_error: 1.0959 - val_mean_squared_error: 1.2009 - val_mean_absolute_error: 0.8513\n",
      "Epoch 46/100\n",
      "164/164 [==============================] - 11s 69ms/step - loss: 0.3545 - mean_absolute_percentage_error: 10.1375 - root_mean_squared_error: 0.5954 - mean_squared_error: 0.3545 - mean_absolute_error: 0.4729 - val_loss: 0.8163 - val_mean_absolute_percentage_error: 16.1393 - val_root_mean_squared_error: 0.9035 - val_mean_squared_error: 0.8163 - val_mean_absolute_error: 0.7130\n",
      "Epoch 47/100\n",
      "164/164 [==============================] - 12s 75ms/step - loss: 0.3412 - mean_absolute_percentage_error: 9.9327 - root_mean_squared_error: 0.5841 - mean_squared_error: 0.3412 - mean_absolute_error: 0.4635 - val_loss: 0.9028 - val_mean_absolute_percentage_error: 17.0279 - val_root_mean_squared_error: 0.9502 - val_mean_squared_error: 0.9028 - val_mean_absolute_error: 0.7334\n",
      "Epoch 48/100\n",
      "164/164 [==============================] - 12s 73ms/step - loss: 0.3381 - mean_absolute_percentage_error: 9.9314 - root_mean_squared_error: 0.5815 - mean_squared_error: 0.3381 - mean_absolute_error: 0.4657 - val_loss: 0.8097 - val_mean_absolute_percentage_error: 15.8901 - val_root_mean_squared_error: 0.8999 - val_mean_squared_error: 0.8097 - val_mean_absolute_error: 0.7235\n",
      "Epoch 49/100\n",
      "164/164 [==============================] - 12s 70ms/step - loss: 0.3345 - mean_absolute_percentage_error: 9.8506 - root_mean_squared_error: 0.5783 - mean_squared_error: 0.3345 - mean_absolute_error: 0.4602 - val_loss: 0.8066 - val_mean_absolute_percentage_error: 15.9387 - val_root_mean_squared_error: 0.8981 - val_mean_squared_error: 0.8066 - val_mean_absolute_error: 0.7097\n",
      "Epoch 50/100\n",
      "164/164 [==============================] - 12s 74ms/step - loss: 0.3364 - mean_absolute_percentage_error: 9.8449 - root_mean_squared_error: 0.5800 - mean_squared_error: 0.3364 - mean_absolute_error: 0.4609 - val_loss: 0.9846 - val_mean_absolute_percentage_error: 18.1047 - val_root_mean_squared_error: 0.9923 - val_mean_squared_error: 0.9846 - val_mean_absolute_error: 0.7680\n",
      "Epoch 51/100\n",
      "164/164 [==============================] - 12s 74ms/step - loss: 0.3145 - mean_absolute_percentage_error: 9.5853 - root_mean_squared_error: 0.5608 - mean_squared_error: 0.3145 - mean_absolute_error: 0.4494 - val_loss: 0.8024 - val_mean_absolute_percentage_error: 16.0417 - val_root_mean_squared_error: 0.8958 - val_mean_squared_error: 0.8024 - val_mean_absolute_error: 0.7025\n",
      "Epoch 52/100\n",
      "164/164 [==============================] - 12s 74ms/step - loss: 0.3021 - mean_absolute_percentage_error: 9.2934 - root_mean_squared_error: 0.5496 - mean_squared_error: 0.3021 - mean_absolute_error: 0.4369 - val_loss: 0.8879 - val_mean_absolute_percentage_error: 16.8981 - val_root_mean_squared_error: 0.9423 - val_mean_squared_error: 0.8879 - val_mean_absolute_error: 0.7269\n",
      "Epoch 53/100\n",
      "164/164 [==============================] - 12s 70ms/step - loss: 0.3024 - mean_absolute_percentage_error: 9.3483 - root_mean_squared_error: 0.5499 - mean_squared_error: 0.3024 - mean_absolute_error: 0.4394 - val_loss: 0.8122 - val_mean_absolute_percentage_error: 16.0536 - val_root_mean_squared_error: 0.9012 - val_mean_squared_error: 0.8122 - val_mean_absolute_error: 0.7116\n",
      "Epoch 54/100\n",
      " 39/164 [======>.......................] - ETA: 7s - loss: 0.2786 - mean_absolute_percentage_error: 8.8748 - root_mean_squared_error: 0.5278 - mean_squared_error: 0.2786 - mean_absolute_error: 0.4199"
     ]
    }
   ],
   "source": [
    "model_test(zrimec_model(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2632714-9505-4512-bebb-372f3d49366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(danq_model(), 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f55e6-bf26-4172-be44-1159ba096400",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(danq_refined_model(), 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7873f96-828e-4299-a410-7fb2a3432ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(dan_zrimec_model(), 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfbadb-f47e-4c1e-b558-7ab8bfd1f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(augur_model(), 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79b0a10-c0d7-4b3b-a20c-2a3a1937a807",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63783c6-429b-4b1d-a9fe-880a1bfe9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def danq_refined_model_hp_search(hp):\n",
    "    inputs = layers.Input(shape=(7999, 4))\n",
    "\n",
    "    conv = layers.Conv1D(\n",
    "        filters=hp.Int('conv_units', min_value=32, max_value=512, step=32),\n",
    "        kernel_size=hp.Int('kernel_size', min_value=3, max_value=36, step=3),\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=hp.Int('pool_size', min_value=2, max_value=20, step=2),\n",
    "        strides=None\n",
    "    )(conv)\n",
    "    norm = layers.BatchNormalization()(pool)\n",
    "    # drop1 = layers.Dropout(\n",
    "    #     rate=0.2\n",
    "    # )(pool)\n",
    "\n",
    "    bilstm = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            units=hp.Int('lstm_units', min_value=32, max_value=512, step=32), \n",
    "            return_sequences=True, \n",
    "            recurrent_dropout=hp.Float('recurrent_dropout', min_value=0.1, max_value=0.5, step=0.05)\n",
    "        ),\n",
    "        merge_mode=hp.Choice('merge_mode', ['concat', 'sum', 'mul'])\n",
    "    )(norm)\n",
    "    drop2 = layers.Dropout(\n",
    "        rate=hp.Float('rate', min_value=0.1, max_value=0.5, step=0.05)\n",
    "    )(bilstm)\n",
    "    flat = layers.Flatten()(drop2)\n",
    "    dense1 = layers.Dense(\n",
    "        units=hp.Int('dense_units', min_value=32, max_value=128, step=32),\n",
    "        activation='relu'\n",
    "    )(flat)\n",
    "    outputs = layers.Dense(\n",
    "        units=1\n",
    "    )(dense1)\n",
    "    \n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='DanQRefModel')\n",
    "\n",
    "    model.compile(\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        # optimizer=keras.optimizers.Adam(learning_rate=0.1, beta_1=0.999, beta_2=0.99, epsilon=1e-6),\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=[keras.metrics.MeanAbsolutePercentageError(), keras.metrics.MeanSquaredError(), keras.metrics.MeanAbsoluteError()],\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f8e838-9aad-4c15-ae11-df1c37f6730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying that the model compiles\n",
    "danq_refined_model_hp_search(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d21df-f31d-40fc-ba0f-071bd51db6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the tuner\n",
    "tuner = keras_tuner.BayesianOptimization(\n",
    "    hypermodel=danq_refined_model_hp_search,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"hp_search\",\n",
    "    project_name=\"PTRaugur\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f73847-82bf-49c7-bf71-d39dcde324c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing an overview of the tunable parameters\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875a280-5676-488c-aad2-36fe9a61e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up an early stop callback function while tuning\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5),\n",
    "]\n",
    "\n",
    "# running the tuning\n",
    "# tuner.search(\n",
    "#     X_train, y_train,\n",
    "#     batch_size=64, \n",
    "#     epochs=100,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9475e359-d923-486a-9867-82166ac93610",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bcfc1-1a04-4a74-9605-1d1f83757491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both zrimec and danq have a really bad performance (at least with 5 iterations, danq is slow because it's big)\n",
    "# model = zrimec_model()\n",
    "# model = danq_model()\n",
    "# model = baseline_model()\n",
    "# model = augur_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d846b8-9bdb-453e-b467-1f4f1a518c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b8982-e3d5-4544-9862-349265fce832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, 'baseline.png')\n",
    "# img = plt.imread('baseline.png')\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172dfc2-f846-4a93-8321-e38a56f857ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     loss=keras.losses.MeanSquaredError(),\n",
    "#     optimizer=keras.optimizers.Adam(learning_rate=0.1, beta_1=0.999, beta_2=0.99, epsilon=1e-6),\n",
    "#     metrics=[keras.metrics.MeanAbsolutePercentageError(), keras.metrics.RootMeanSquaredError(), keras.losses.MeanSquaredError(), keras.metrics.MeanAbsoluteError()],\n",
    "# )\n",
    "\n",
    "# LOSS\n",
    "# works keras.losses.MeanSquaredError(),\n",
    "\n",
    "# METRIC\n",
    "# useless keras.metrics.Accuracy(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be5b09-0c52-4911-a579-c61318999317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"PTR_baseline.keras\", save_best_only=True)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c18cf-111f-4045-ab88-851efdab4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative methode to prepadding the sequences\n",
    "# X_train_ragged = tf.ragged.constant(X_train, dtype=tf.int8, ragged_rank=1, row_splits_dtype=tf.int32)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(tensor)\n",
    "# dataset = dataset.map(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7843173-f03d-4cdc-9e81-bf033163b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(\n",
    "#     X_train, \n",
    "#     y_train, \n",
    "#     batch_size=64, \n",
    "#     epochs=10, \n",
    "#     validation_data=(X_val, y_val), \n",
    "#     callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5389b58-c88c-491a-bd0b-b1ae96f74559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8bb01-bbe1-4c9e-b7a7-be82d3a61b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test[0], y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872ae84-78d2-4c18-b170-6561f595aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_dict = history.history\n",
    "# history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82c070-4f3c-47c9-8901-62c10e05b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b88240-e1e5-4f66-9de6-e549a3ae79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def full_model():\n",
    "#     # input\n",
    "#     inputs = keras.Input(shape=(None, 10))\n",
    "#     # 1D convolution\n",
    "#     conv = keras.Conv1D(\n",
    "#         filters=128, \n",
    "#         kernel_size=10, \n",
    "#         strides=1, \n",
    "#         activation='relu'\n",
    "#     )(inputs)\n",
    "#     # batch normalization\n",
    "#     norm = keras.BatchNormalization()(conv)\n",
    "#     # maxpool\n",
    "#     pool = keras.MaxPooling1D(\n",
    "#         pool_size=4,\n",
    "#         strides=4\n",
    "#     )(norm)\n",
    "#     # dropout\n",
    "#     drop = keras.Dropout(rate=0.2)(pool)\n",
    "#     # bi-directional LSTM\n",
    "#     bilstm = keras.Bidirectional(\n",
    "#         keras.LSTM(\n",
    "#             units=128,\n",
    "#             dropout=0\n",
    "#         ),\n",
    "#         merge_mode='concat'\n",
    "#     )(drop)\n",
    "#     # batch normalization\n",
    "#     norm = keras.BatchNormalization()(bilstm)\n",
    "#     # maxpool\n",
    "#     pool = keras.MaxPooling1D(\n",
    "#         pool_size=4,\n",
    "#         strides=4\n",
    "#     )(norm)\n",
    "#     # dropout\n",
    "#     drop = keras.Dropout(rate=0.2)(pool)\n",
    "#     # flatten\n",
    "#     flat = keras.Flatten()(drop)\n",
    "\n",
    "#     # second input\n",
    "#     inputs2 = keras.Input(shape=(29,))\n",
    "\n",
    "#     # concatenation\n",
    "#     conc = keras.Concatenate(axis=1)([inputs, inputs2])\n",
    "\n",
    "#     # fully connected\n",
    "#     dense = keras.Dense(\n",
    "#         units=64,\n",
    "#         activation='relu'\n",
    "#     )(conc)\n",
    "#     # batch normalization\n",
    "#     norm = keras.BatchNormalization()(dense)\n",
    "#     # dropout\n",
    "#     drop = keras.Dropout(rate=0.2)(norm)\n",
    "#     # dense\n",
    "#     outputs = keras.Dense(units=1)(drop)\n",
    "\n",
    "#     # model\n",
    "#     model = keras.Model(inputs=[inputs, inputs2], outputs=outputs, name='full_model')\n",
    "    \n",
    "#     return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
