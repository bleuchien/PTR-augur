{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12e085-6ce6-41e0-8f1e-1d35b23bf358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library dependencies\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import lzma\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ecd0a7-8f25-4b5b-bfb0-b5375b32c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to store data as serialized binary structure lzma compressed\n",
    "def can_pickles(data, filename):\n",
    "    with lzma.LZMAFile(filename, 'wb') as f:\n",
    "        pickle.dump(data, f, pickle.DEFAULT_PROTOCOL)\n",
    "\n",
    "# method to retrieve data from a compressed pickle file (created with the method above)\n",
    "def uncan_pickles(filename):\n",
    "    with lzma.LZMAFile(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330afba-bf62-4e92-ad84-62921e42d31f",
   "metadata": {},
   "source": [
    "baseline data\n",
    "\n",
    "X holds a list of sequences one hot encoded\n",
    "y holds a list of PTR values as floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1d16d-426c-460f-930d-0e91adba9e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the prepared data back\n",
    "X = uncan_pickles('../data/onehot_x_lung.pickle.xz')\n",
    "y = uncan_pickles('../data/onehot_y_lung.pickle.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2e91af-1782-4909-8191-87442cac791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_padded = tf.keras.preprocessing.sequence.pad_sequences(X, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3603897-eca1-41be-a833-79e59f4b5be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert type of target values from string to float\n",
    "y = np.array(y).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41525e09-813f-46b8-9f47-ebbd7381510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85471826-2b3a-4371-8441-ae940ba8e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa09b2-b288-4618-88a6-7799e1335da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some idea of the range of the PTR in the selected SAMPLE\n",
    "print(np.min(y), np.max(y), np.mean(y), np.std(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9ba3da-9ab0-43f5-a923-63e94c580a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple/dumb baseline mean absolute error of always predicting 4.974\n",
    "mae = np.mean(np.abs(np.array(y) - 4.974))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f3792-6d06-48e0-81af-f689cbb35c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of input sequences\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d073003-6e5c-498b-b02f-32f415d55d66",
   "metadata": {},
   "source": [
    "split data in train and test subsets\n",
    "\n",
    "verify that the split worked properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ab59a-ba46-4c89-a02e-2e33bde62cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in train and test sub sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=1202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f719d49d-470d-4492-b45b-a3359d711fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train set again in train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1202)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4565eb-bf79-4504-bb8c-3aa2448fcc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample\n",
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d75b63-7632-476e-9a01-11d4f428ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the matching target\n",
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd20cd1-1386-4e36-a94f-9209edb96cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the target value in the raw dataset\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 3.746:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cded98c-538f-4195-9380-bd739a150c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare if the raw dataset entry matches the subset entry\n",
    "if X_padded[6663].all() == X_train[1].all():\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de67ac-0026-42a6-b09b-f1fd60a0d74c",
   "metadata": {},
   "source": [
    "model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0555c3-6e36-41eb-bb88-652a14aa79cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zrimec_model():\n",
    "    inputs = layers.Input(shape=(7999, 4))\n",
    "\n",
    "    conv1 = layers.Conv1D(\n",
    "        filters=32,\n",
    "        kernel_size=10,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    )(inputs)\n",
    "    norm1 = layers.BatchNormalization()(conv1)\n",
    "    drop1 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm1)\n",
    "    pool1 = layers.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(drop1)\n",
    "    conv2 = layers.Conv1D(\n",
    "        filters=64,\n",
    "        kernel_size=10,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    )(pool1)\n",
    "    norm2 = layers.BatchNormalization()(conv2)\n",
    "    drop2 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm2)\n",
    "    pool2 = layers.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(drop2)\n",
    "    conv3 = layers.Conv1D(\n",
    "        filters=128,\n",
    "        kernel_size=10,\n",
    "        strides=1,\n",
    "        activation='relu',\n",
    "        padding='valid'\n",
    "    )(pool2)\n",
    "    norm3 = layers.BatchNormalization()(conv3)\n",
    "    drop3 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm3)\n",
    "    pool3 = layers.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(drop3)\n",
    "    flat = layers.Flatten()(pool3)\n",
    "    dense = layers.Dense(\n",
    "        units=64,\n",
    "        activation='relu'\n",
    "    )(flat)\n",
    "    norm4 = layers.BatchNormalization()(flat)\n",
    "    drop4 = layers.Dropout(\n",
    "        rate=0.1\n",
    "    )(norm4)\n",
    "    outputs = layers.Dense(\n",
    "        units=1\n",
    "    )(drop4)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='ZrimecModel')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6ecde-954a-47a9-a7ad-ee9bfa13a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def danq_model():\n",
    "    inputs = layers.Input(shape=(7999, 4))\n",
    "\n",
    "    conv = layers.Conv1D(\n",
    "        filters=320,\n",
    "        kernel_size=26,\n",
    "        padding='valid',\n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=13,\n",
    "        strides=13\n",
    "    )(conv)\n",
    "    drop1 = layers.Dropout(\n",
    "        rate=0.2\n",
    "    )(pool)\n",
    "\n",
    "    forward_layer = layers.LSTM(units=320, return_sequences=True)\n",
    "    backward_layer = layers.LSTM(units=320, return_sequences=True, go_backwards=True)\n",
    "    bilstm = layers.Bidirectional(\n",
    "        forward_layer, backward_layer=backward_layer\n",
    "    )(drop1)\n",
    "    drop2 = layers.Dropout(\n",
    "        rate=0.2\n",
    "    )(bilstm)\n",
    "    flat = layers.Flatten()(drop2)\n",
    "    dense1 = layers.Dense(\n",
    "        units=925,\n",
    "        activation='relu'\n",
    "    )(flat)\n",
    "    outputs = layers.Dense(\n",
    "        units=1\n",
    "    )(dense1)\n",
    "    \n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='DanQModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4c5168-f720-48b4-b777-01067098205e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # input\n",
    "    # setting fixed shape since the sequences are padded to the max length (threshold of preproc2)\n",
    "    inputs = layers.Input(shape=(7999, 4))\n",
    "    # 1D convolution\n",
    "    conv = layers.Conv1D(\n",
    "        filters=320, \n",
    "        kernel_size=26, \n",
    "        strides=1, \n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    # batch normalization\n",
    "    norm = layers.BatchNormalization()(conv)\n",
    "    # maxpool\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=13,\n",
    "        strides=13\n",
    "    )(norm)\n",
    "    # dropout\n",
    "    drop = layers.Dropout(rate=0.1)(pool)\n",
    "    # bi-directional LSTM\n",
    "    bilstm = layers.Bidirectional(\n",
    "        layers.LSTM(\n",
    "            units=320, \n",
    "            dropout=0,\n",
    "            return_sequences=True,\n",
    "        ),\n",
    "        merge_mode='mul',\n",
    "        # input_shape=(8000, 4),\n",
    "    )(drop)\n",
    "    # maxpool\n",
    "    pool = layers.MaxPooling1D(\n",
    "        pool_size=13,\n",
    "        strides=13,\n",
    "    )(bilstm)\n",
    "    drop = layers.Dropout(rate=0.1)(pool)\n",
    "    # flatten\n",
    "    flat = layers.Flatten()(drop)\n",
    "    # fully connected\n",
    "    dense = layers.Dense(\n",
    "        units=64,\n",
    "        activation='relu',\n",
    "    )(flat)\n",
    "    # batch normalization\n",
    "    norm = layers.BatchNormalization()(dense)\n",
    "    # dropout\n",
    "    drop = layers.Dropout(rate=0.1)(norm)\n",
    "    # dense\n",
    "    outputs = layers.Dense(units=1)(drop)\n",
    "\n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='BaselineModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468d333-3246-419a-95cd-4eb520fa40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augur_model():\n",
    "    inputs = layers.Input(shape=(7999, 4))\n",
    "    conv1 = layers.LSTM(units=32, recurrent_dropout=0.25)(inputs)\n",
    "    drop1 = layers.Dropout(rate=0.2)(conv1)\n",
    "    outputs = layers.Dense(units=1)(drop1)\n",
    "    \n",
    "    # model\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='AugurModel')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bcfc1-1a04-4a74-9605-1d1f83757491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both zrimec and danq have a really bad performance (at least with 5 iterations, danq is slow because it's big)\n",
    "# model = zrimec_model()\n",
    "# model = danq_model()\n",
    "# model = baseline_model()\n",
    "model = augur_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eed410-4510-4756-9c54-b72d2a88b654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model, epochs=5):\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        # optimizer=keras.optimizers.Adam(learning_rate=0.1, beta_1=0.999, beta_2=0.99, epsilon=1e-6),\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        metrics=[keras.metrics.MeanAbsolutePercentageError(), keras.metrics.RootMeanSquaredError(), keras.losses.MeanSquaredError(), keras.metrics.MeanAbsoluteError()],\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        batch_size=64, \n",
    "        epochs=epochs, \n",
    "        validation_data=(X_val, y_val), \n",
    "        # callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Random prediction sample (truth, prediction):', y_test[0], y_pred[0])\n",
    "    \n",
    "    plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d46776-4a76-4870-aa3f-565606a6ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(hist):\n",
    "    history_dict = hist.history\n",
    "    loss_values = history_dict[\"loss\"]\n",
    "    val_loss_values = history_dict[\"val_loss\"]\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "    plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
    "    plt.title(\"Training and validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362f55a9-a90d-4979-87b8-13399dd499b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(zrimec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2632714-9505-4512-bebb-372f3d49366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(danq_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7873f96-828e-4299-a410-7fb2a3432ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccfbadb-f47e-4c1e-b558-7ab8bfd1f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(augur_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9475e359-d923-486a-9867-82166ac93610",
   "metadata": {},
   "source": [
    "manual tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d846b8-9bdb-453e-b467-1f4f1a518c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b8982-e3d5-4544-9862-349265fce832",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, 'baseline.png')\n",
    "# img = plt.imread('baseline.png')\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172dfc2-f846-4a93-8321-e38a56f857ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.1, beta_1=0.999, beta_2=0.99, epsilon=1e-6),\n",
    "    metrics=[keras.metrics.MeanAbsolutePercentageError(), keras.metrics.RootMeanSquaredError(), keras.losses.MeanSquaredError(), keras.metrics.MeanAbsoluteError()],\n",
    ")\n",
    "\n",
    "# LOSS\n",
    "# works keras.losses.MeanSquaredError(),\n",
    "\n",
    "# METRIC\n",
    "# useless keras.metrics.Accuracy(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4be5b09-0c52-4911-a579-c61318999317",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # keras.callbacks.ModelCheckpoint(\"PTR_baseline.keras\", save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c18cf-111f-4045-ab88-851efdab4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative methode to prepadding the sequences\n",
    "# X_train_ragged = tf.ragged.constant(X_train, dtype=tf.int8, ragged_rank=1, row_splits_dtype=tf.int32)\n",
    "# dataset = tf.data.Dataset.from_tensor_slices(tensor)\n",
    "# dataset = dataset.map(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7843173-f03d-4cdc-9e81-bf033163b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=64, \n",
    "    epochs=10, \n",
    "    validation_data=(X_val, y_val), \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5389b58-c88c-491a-bd0b-b1ae96f74559",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8bb01-bbe1-4c9e-b7a7-be82d3a61b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test[0], y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872ae84-78d2-4c18-b170-6561f595aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c82c070-4f3c-47c9-8901-62c10e05b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b88240-e1e5-4f66-9de6-e549a3ae79a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model():\n",
    "    # input\n",
    "    inputs = keras.Input(shape=(None, 10))\n",
    "    # 1D convolution\n",
    "    conv = keras.Conv1D(\n",
    "        filters=128, \n",
    "        kernel_size=10, \n",
    "        strides=1, \n",
    "        activation='relu'\n",
    "    )(inputs)\n",
    "    # batch normalization\n",
    "    norm = keras.BatchNormalization()(conv)\n",
    "    # maxpool\n",
    "    pool = keras.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(norm)\n",
    "    # dropout\n",
    "    drop = keras.Dropout(rate=0.2)(pool)\n",
    "    # bi-directional LSTM\n",
    "    bilstm = keras.Bidirectional(\n",
    "        keras.LSTM(\n",
    "            units=128,\n",
    "            dropout=0\n",
    "        ),\n",
    "        merge_mode='concat'\n",
    "    )(drop)\n",
    "    # batch normalization\n",
    "    norm = keras.BatchNormalization()(bilstm)\n",
    "    # maxpool\n",
    "    pool = keras.MaxPooling1D(\n",
    "        pool_size=4,\n",
    "        strides=4\n",
    "    )(norm)\n",
    "    # dropout\n",
    "    drop = keras.Dropout(rate=0.2)(pool)\n",
    "    # flatten\n",
    "    flat = keras.Flatten()(drop)\n",
    "\n",
    "    # second input\n",
    "    inputs2 = keras.Input(shape=(29,))\n",
    "\n",
    "    # concatenation\n",
    "    conc = keras.Concatenate(axis=1)([inputs, inputs2])\n",
    "\n",
    "    # fully connected\n",
    "    dense = keras.Dense(\n",
    "        units=64,\n",
    "        activation='relu'\n",
    "    )(conc)\n",
    "    # batch normalization\n",
    "    norm = keras.BatchNormalization()(dense)\n",
    "    # dropout\n",
    "    drop = keras.Dropout(rate=0.2)(norm)\n",
    "    # dense\n",
    "    outputs = keras.Dense(units=1)(drop)\n",
    "\n",
    "    # model\n",
    "    model = keras.Model(inputs=[inputs, inputs2], outputs=outputs, name='full_model')\n",
    "    \n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
